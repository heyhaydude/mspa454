---
title: "Forest Cover Type Prediction"
author: "Annie Condon, Matt Hayden, Matt Robertson, Yvette Gonzalez"
subtitle: Forest Cover Team B
output:
  pdf_document:
    fig_caption: yes
    includes:
      before_body: latex/before_body.tex
    number_sections: yes
    toc: yes
  html_document:
    fig_caption: yes
    includes:
      before_body: latex/before_body.tex
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r setup data 1, warning=FALSE, message=FALSE}
# read in the data, create dataframe
gz = gzfile('data/covtype.data.gz','rt') 
forest.orig = read.csv(gz,header=F)
forest.orig.colnames = t(read.csv('data/covtyp.colnames.csv',header=F))
colnames(forest.orig) = forest.orig.colnames

# identify continuous variables
forest.var.continuous = c('Elevation','Aspect','Slope', 'HDist.Hydrology', 'VDist.Hydrology', 
                          'HDist.Roadway', 'Hillshade.9am', 'Hillshade.12pm', 'Hillshade.3pm',
                          'HDist.FirePoint')

# for speed, will perform eda on subset until ready to do a full run
set.seed(33)
forest = forest.orig[sample(nrow(forest.orig),20000),]
forest.var.discrete.indices = grep("^Area|^SoilType|CoverType", colnames(forest))
forest[,forest.var.discrete.indices] = as.factor(unlist(forest[,forest.var.discrete.indices]))

forest.numeric = as.data.frame(sapply(forest,as.numeric))

covertype.names = c('Spruce-fir','Lodgepole Pine','Ponderosa Pine','Cottonwood-Willow','Aspen','Douglas-fir','Krummholz')

forest$CoverType[forest$CoverType==1] = 'Spruce-fir'
forest$CoverType[forest$CoverType==2] = 'Lodgepole Pine'
forest$CoverType[forest$CoverType==3] = 'Ponderosa Pine'
forest$CoverType[forest$CoverType==4] = 'Cottonwood-Willow'
forest$CoverType[forest$CoverType==5] = 'Aspen'
forest$CoverType[forest$CoverType==6] = 'Douglas-fir'
forest$CoverType[forest$CoverType==7] = 'Krummholz'


# add Area column
# are any in multiple areas? NO. all belong to only one area
idx = grep("Area", colnames(forest))
temp = forest.numeric[,idx]
temp.rows = temp[apply(temp,1,sum) > 1,]
temp$Z.Area = apply(temp,1,function(x) {
  return(which.max(x))
})
forest.numeric$Z.Area = temp$Z.Area

forest.scaled = as.data.frame(scale(forest.numeric))

library(lattice)
library(ggplot2)
library(corrplot)
library(MASS)
library(caret)
library(car)
library(DMwR)
library(dplyr)
library(randomForest)
library(nnet)
library(neuralnet)

```

\newpage

# Introduction

The U.S. Forest Service relies on an accurate understanding of its forests composition in order to best protect and manage the forest land. Conducting accurate inventory of forest composition by direct observation or remotely sensed data is often too expensive and time consuming to do at large-scale. Predictive analytics can be employed to use the results of a small-scale survey to create a model that can be applied across a large region, using descriptive features extracted from maps of the area.


In this paper, our objective is to predict the forest cover type given a set of cartographic features and a variety of multiclass classification models. Our models will be evaluated using predictive accuracy. 


# The Modeling Problem

Our modeling problem is to predict the forest cover type as a multiclass classification problem based on the associated features. A multiclass classification problem classifies instances into one of the more than two classes. Our forest cover type is defined as one of seven, mutually exclusive, forest cover type classes, shown in table 1 below.

```{r}
cover_types <- c("Spruce/Fir", "Lodgepole Pine", "Ponderosa Pine", "Cottonwood/Willow", "Aspen", 
                 "Douglas/Fir", "Krummholz")
instances <- c(211840, 283301, 35754, 2747, 9493, 17367, 20510)
ct.df <- data.frame(cover_types, instances)
colnames(ct.df) <- c("Cover Type", "Number of Observations")
```

```{r}
knitr::kable(ct.df, caption = "Cover Type Classes", format="pandoc") 
```

Most classification algorithms can be applied, either directly or through slight modifications, to multiclass classification problems. Two different approaches exists for multi-class classification: algorithms that naturally permit the use of more than two classes and those that first reduce a multi-class problem to a collection of binary-class problems and then combine their predictions in various ways. The following is a list of algorithms we will consider for our problem:

* Discriminant Analysis
* Logistic Regression
* K-Nearest Neighbors 
* Random Forests
* Neural Network
* Support Vector Machine

We will use ‘Kappa’ as a metric to optimize for tuning our parameters because this metric can improve the quality of the model for problems where there are a low percentage of samples in one class.

## Evaluating Classification Models

We will evaluate a number of different models by applying them to a holdout 'test' dataset and assessing their performance. Because there is an imbalance in the classes to be predicted, we will consider alternatives to 'accuracy' to evaluate our final models. Using accuracy only to evaluate models can perform poorly in predicting the less frequent classes. We will instead look at two metrics that handle class imbalance: balanced accuracy and f1 score. Balanced accuracy is (sensitivity+specificity)/2, or the average accuracy over all classes. F1 Score is precision x recall/(precision + recall),the weighted average of precision and recall. The precision measures the accuracy of a predicted positive outcome and recall (sensitivity) measures the strength of the model to predict a positive outcome Therefore, this score takes both false positives and false negatives into account.    

# The Data

Our data set consists of 581,012 observations of the 30 x 30 meter cells of forest and 54 features associated with each cell. The features are derived from 12 attributes, with area and soil type binarized so that there are 4 binary area designators and 40 binary soil type designators. There is no missing data. The feature descriptions are listed in the table below:


```{r}
features <- c("Elevation", "Aspect", "Slope", "HDist.Hydrology", "VDist.Hydrology",
              "HDist.Roadway", "Hillshade.9am", "Hillshade.12pm", "Hillshade.3pm", 
              "HHDist.FirePoint", "Area", "SoilType")
descriptions <- c("Elevation in meters", "Aspect in degrees aziumuth", "Slope in degrees", 
                 "Horizontal distance to nearest surface water feature in meters", 
                 "Vertical distance to nearest surface water feature in meters", 
                 "Horizontal distance to nearest roadway in meters", "Hillshade index at 9am, summer solstice", 
                "Hillshade index at noon, summer soltice", "Hillshade index at 3pm, summer solstice", 
              "Horizontal Distance to nearest wildfire ignition points", "Wilderness area designation - 4 binary areas",
              "Soil Type designation - 40 binary values")
features.df <- data.frame(features, descriptions)
colnames(features.df) <- c("Feature", "Descriptions")
```

```{r}
knitr::kable(features.df, caption = "Features", format="pandoc") 
```


## Response Variable


Figure one shows the frequency of each class of cover type in our data set. 85 percent of the observations fall into classes 1 and 2, Spruce/Fir and Lodgepole Pine. Class 4, Cottonwood/Willow has the least amount of observations at 2,747.


```{r,fig.cap="Frequency of each Cover Type Class", fig.height=3}
library(scales)

ggplot(as.data.frame(table(forest.orig$CoverType)), aes(x=Var1, y = Freq)) + ggtitle("Forest Cover
Frequency by Class") + geom_bar(stat = "identity", fill="#1f78b4", width=.5,
                                color="black") + xlab("Cover Type") + scale_y_continuous(name="Frequency", labels = comma)
```

\newpage
## Continuous Variables


Table 3 includes some standard statistical measures of central tendency and variation for our continuous variables, for investigation of unusual values. We would first like to note that an Aspect value of 0 and 360 would both be equal to true north, so we should standardize that value. Next, we will point out that while a negative distance value for VDist.Hydrology may appear to be an error, it is in fact reasonable due to it being a vertical measurement from differing altitudes, making a negative distance possible. Our Hillshade values fall into the hillshade index integer value range of 0 to 255. Also, our horizontal distances all have minimum values of 0.


```{r fig.cap="Summary Statistics"}
options(digits=3)
my.summary <- function(x,...){
  c(mean=round(mean(x, ...), digits = 4),
    sd=round(sd(x, ...), digits=4),
    median=median(x, ...),
    min=min(x, ...),
    max=max(x,...),
    nmiss=sum(is.na(x,...)),
    type="Continuous")
}


forest.stats= apply(forest.orig[,1:10], 2, my.summary)

library(knitr)
kable(t(forest.stats), caption= "Summary Statistics for Continuous Data", format="pandoc")
```


## Binary Variables


Our data's binary variables consist of 4 different wilderness area designators and 40 different soil type designators. Table 4 and 5 below represent the frequency of each of the areas and soil types, in descending order.


```{r}
## area
forest.area= forest.orig[11:14]

summary.area <- data.frame(
  Name = character(),
  Count = numeric(),
  stringsAsFactors = F)

for (i in 1:4){
  summary.area[i,1] <- names(forest.area[i])
  summary.area[i,2] <- sum(forest.area[,i])
}

area<-summary.area[with(summary.area,order(-Count)),]
kable(area,caption= "Area Type Counts", format="pandoc", row.names = F)

## soil
forest.soil= forest.orig[15:54]

summary.soil <- data.frame(
  Name = character(),
  Count = numeric(),
  stringsAsFactors = F)

for (i in 1:40){
  summary.soil[i,1] <- names(forest.soil[i])
  summary.soil[i,2] <- sum(forest.soil[,i])
}


soil<-summary.soil[with(summary.soil,order(-Count)),]
kable(soil, caption= "Soil Type Counts", format="pandoc", row.names = F)
```

\newpage
# Exploratory Data Analysis

Our next step is to explore the relationships in our data. We will begin by looking at boxplots of our scaled continuous variables in order to understand their relative distribution. We note that Hillshade.12pm and VDist.Hydrology have more pronounced skews than the other variables. We will need to investigate transformations if we use modeling techniques that can be negatively effected by outliers.
\newline
\newline

```{r fig.cap="Boxplots of Scaled Continuous Variables"}

st = stack(as.data.frame(forest.scaled[,forest.var.continuous]))
ggplot(as.data.frame(st)) +
  geom_boxplot(aes(x = ind, y = values)) +
  theme(axis.text.x = element_text(angle=45, hjust = 1)) +
  scale_x_discrete(name ="") + scale_y_continuous(name ="") +
  ggtitle("Boxplots of Scaled Continuous Variables")
```

\newpage
Our data exploration is informed by our statistical problem, which is one of multiclass classification. We will therefore be interested in exploring our predictors by each of our classes. The density plots below superimpose the density estimates for each variable by class, 1-7. We note that our variable Aspect shows multimodel distributions, indicating that it may have more than one grouping included. This is due to the value of 0 and 360 both being equal to true north, which we will have to address in data preparation.  We will also note that several of our variables show distinct distributions by class, indicating that they would serve as a good predictor.
\newline
\newline


```{r fig.cap="Density Plots of Continuous Variables by Class"}
density.plots = densityplot(~ Elevation + Aspect + Slope + HDist.Hydrology + VDist.Hydrology + 
                              HDist.Roadway + Hillshade.9am + Hillshade.12pm + Hillshade.3pm +
                              HDist.FirePoint,
                            data=forest, 
                            groups = CoverType, 
                            plot.points = FALSE, 
                            auto.key = list(space="right",title="Cover Type",cex=.6),
                            scales= list(x="free",y="free"), 
                            xlab = '', 
                            ylab=list(cex=.8), 
                            aspect="fill",
                            par.strip.text=list(cex=.9))
plot(density.plots)
```


\newpage
Figure 4 shows density plots by each of the four wilderness areas.Several variable values appear to be distinguishable by wilderness area. 
\newline
\newline


```{r fig.cap="Density Plots of Continuous Variables by Area"}
density.plots = densityplot(~ Elevation + Aspect + Slope + HDist.Hydrology + VDist.Hydrology + 
                              HDist.Roadway + Hillshade.9am + Hillshade.12pm + Hillshade.3pm +
                              HDist.FirePoint,
                            data=forest.numeric, 
                            groups = Z.Area, 
                            plot.points = FALSE, 
                            auto.key = list(space="right",title="Area",cex=.6),
                            scales= list(x="free",y="free"), 
                            xlab = '', 
                            ylab=list(cex=.8), 
                            aspect="fill",
                            par.strip.text=list(cex=.9))
plot(density.plots)
```


\newpage
Next, we will look at the correlations between the our predictor variables. Highly correlated predictors can have a negative effect on some of our modeling algorithms. Below is a correlation matrix with dark blue colors indicating a strong positive correlation and dark red colors indicating a strong negative correlation. We see the following variables with higher correlations that should be investigated further:


High Positive Collinearity


* VDist.Hydrology and HDist.Hydrology
* Aspect and Hillshade.3pm
* Hillshade.3pm and Hillshade.12pm

High Negative Collinearity


* Aspect and Hillshade.9am
* Slope and Hillshade.12pm
* Hillshade.3pm and Hillshade.9am
\newline
\newline

```{r fig.cap="Correlation Matrix"}
corrplot(cor(forest[, forest.var.continuous]), 
         tl.col = "black", tl.cex = 0.8, tl.srt = 45,
         cl.cex = 0.8, pch.cex = 0.8, diag = FALSE,
         type="lower",
         addCoefasPercent = TRUE, addCoef.col = TRUE,number.cex = .6) #Matt added to show correlation amounts
```


\newpage
Figure 6 shows a barchart of our 40 different soil types which shows the proportion of frequency of each class. We can see that soil types 1-7 have similar proportions, as do 19-33 and 38-40. A few soil types have only one cover type class, making them especially good predictors.
\newline
\newline


```{r fig.cap="Soil Barchart"}
idx = grep("SoilType|CoverType", colnames(forest.numeric))
df = as.data.frame(forest.numeric[,idx])
idx.type = grep("CoverType", colnames(df))

df.temp = df[,-idx.type]

soil.sums = apply(df.temp,2,function(x) {
  tbl = table(x,df$CoverType)
  if (dim(tbl)[1] < 2) {
    tbl = rbind('0' = tbl, '1' = rep(0,7), deparse.level = 1)
  }
  return (apply(tbl,1,sum)[2])
})
#soil.sums

soil.sums.byclass = apply(df[,-idx.type],2,function(x) {
  tbl = table(x,df$CoverType)
  tbl = tbl[seq(2,14,by=2)]
  return (tbl)
})
#soil.sums.byclass

soil.ratios = as.data.frame(t(soil.sums.byclass)/soil.sums)
library(RColorBrewer)
soil.ratios.m = na.omit(as.matrix(soil.ratios))
barchart(soil.ratios.m,col=brewer.pal(7, "Pastel2"),xlab='',
         key=list(space="right",
                  lines=list(col=brewer.pal(7, "Pastel2"),lwd=3),
                  text=list(covertype.names)
))

```


\newpage
Figure 7 shows a barchart of our 4 different wilderness areas with the proportion of frequency of each class. We can see that the class composition in area 4 is distinguishable from the other areas, making it a good predictor.
\newline
\newline


```{r fig.cap="Area Barchart"}
idx = grep("Area1|Area2|Area3|Area4|CoverType", colnames(forest.numeric))
df = as.data.frame(forest.numeric[,idx])
idx.type = grep("CoverType", colnames(df))

df.temp = df[,-idx.type]

area.sums = apply(df.temp,2,function(x) {
  tbl = table(x,df$CoverType)
  if (dim(tbl)[1] < 2) {
    tbl = rbind('0' = tbl, '1' = rep(0,7), deparse.level = 1)
  }
  return (apply(tbl,1,sum)[2])
})
#area.sums

area.sums.byclass = apply(df[,-idx.type],2,function(x) {
  tbl = table(x,df$CoverType)
  tbl = tbl[seq(2,14,by=2)]
  return (tbl)
})
#area.sums.byclass

area.ratios = as.data.frame(t(area.sums.byclass)/area.sums)
library(RColorBrewer)
area.ratios.m = na.omit(as.matrix(area.ratios))
barchart(area.ratios.m,col=brewer.pal(7, "Pastel2"),xlab='',
         key=list(space="right",
                  lines=list(col=brewer.pal(7, "Pastel2"),lwd=3),
                  text=list(covertype.names)
                  )
)


```

\newpage
Next, we look at the horizontal distance to the roadway, by class. We can see that most observations in classes 5-7, Aspen, Cottonwood-Willow and Douglas-fir are closest to the roadways.
\newline
\newline


```{r, fig.cap="Distance to Roadway, by class"}
ggplot(forest, aes(x=HDist.Roadway)) + 
  geom_histogram(aes(group=CoverType, colour=CoverType, fill=CoverType), bins=30, alpha=0.7)+
  ggtitle('')+
  theme(legend.title = element_blank())+
  labs(x="Distance to Roadway",y="Count")
```

\newpage
Figure 9 shows horizontal distance to the water, by class. Again, we see that most observations in classes 5-7 are closest to a water source.
\newline
\newline


```{r, fig.cap="Distance to water, by class"}
ggplot(forest, aes(x=HDist.Hydrology)) + 
  geom_histogram(aes(group=CoverType, colour=CoverType, fill=CoverType), bins=30, alpha=0.7)+
  ggtitle('')+
  theme(legend.title = element_blank())+
  labs(x="Distance to Water",y="Count")
```

\newpage
Figure 10 shows the contrasting relationship between Hillshade.9am and Hillshade.3pm over varying aspect values. We see that between 0 and 200 degrees, hillshade varies significantly between 9am and 3pm, but between 200 and 360 degrees, hillshade between 9am and 3pm are relatively the same.

```{r, fig.cap="Hillshade.9am and Hillshade.3pm"}
ggplot(forest, aes(x=Aspect)) + 
    geom_point(aes(y=Hillshade.9am, color="Hillshade.9am"), alpha=.1) +
    geom_point(aes(y=Hillshade.3pm, color="Hillshade.3pm"), alpha=.1)
```

# Data Preparation

##Transformations

The distribution for Hillshade.12pm was noticeably skewed in the boxplots above, so we create a log transformation of Hillshade.12pm and  for later use in our models. Additionally we created an interaction variable using Vist.Hydrology and HDistHydrology. A linear distance variable was also created using the vertical and horizontal distance to hydrology variables.Additionally, soil types were grouped into Climatic and Geologic zones as a potential means to reduce the amount of SoilType variables used for various modeling techniques.

```{r setup data 2}
# transform Hillshade.12pm and Vdist.Hydrology
forest.new= forest.orig

#forest.new$trans.Hillshade.12pm = log(forest.new$Hillshade.12pm)

#forest.new$trans.VDist.Hydrology = preProcess(forest.new$VDist.Hydrology, method = "YeoJohnson")
forest.new$trans.LDist.Hydrology <- sqrt(forest.new$VDist.Hydrology^2 + forest.new$HDist.Hydrology^2) 


# Soil Type to Climate Zone Mapping
forest.new$trans.zone27 <- rowSums(forest.new[,c("SoilType1", "SoilType2","SoilType3","SoilType4", "SoilType5","SoilType6")])
forest.new$trans.zone35 <- rowSums(forest.new[,c("SoilType7", "SoilType8")])
forest.new$trans.zone42 <- forest.new$SoilType9
forest.new$trans.zone47 <- rowSums(forest.new[,c("SoilType10", "SoilType11","SoilType12","SoilType13")])
forest.new$trans.zone51 <- rowSums(forest.new[,c("SoilType14", "SoilType15")])
forest.new$trans.zone61 <- rowSums(forest.new[,c("SoilType16", "SoilType17")])
forest.new$trans.zone67 <- forest.new$SoilType18
forest.new$trans.zone71 <- rowSums(forest.new[,c("SoilType19", "SoilType20","SoilType21")])
forest.new$trans.zone72 <- rowSums(forest.new[,c("SoilType22", "SoilType23")])
forest.new$trans.zone77 <- rowSums(forest.new[,c("SoilType24", "SoilType25","SoilType26","SoilType27", "SoilType28",
  "SoilType29", "SoilType30","SoilType31","SoilType32", "SoilType33", "SoilType34")])
forest.new$trans.zone87 <- rowSums(forest.new[,c("SoilType35", "SoilType36","SoilType37","SoilType38", "SoilType39","SoilType40")])


```


Furthermore, we attempt to reduce the variable complexity of 40 soil variables with principal component analysis. We found that 90.7% of the variance can be explained with 16 variables instead of 40. Similar analysis using 6 of 10 Soil Zones explains 99.2% of variation. This may help with modeling efforts the rely on reducing model complexity.

```{r setup data 3}

#PCA
set.seed(444)
idxs.soil = grep("Soil", colnames(forest.new))
temp.soil = forest.new[,idxs.soil]
soil.pca = prcomp(temp.soil, scale = F)
soil.pca.x = soil.pca$x
colnames(soil.pca.x) <- c(paste0("soil.pca.pc",as.character(1:ncol(soil.pca.x))))
 #summary(soil.pca)$importance[3,]
forest.new <- cbind(forest.new, soil.pca.x[,1:16]) #90.7% of importantance

idxs.zone = grep("trans.zone", colnames(forest.new))
temp.zone = forest.new[,idxs.zone]
zone.pca = prcomp(temp.zone, scale = F)
zone.pca.x = zone.pca$x
colnames(zone.pca.x) <- c(paste0("zone.pca.pc",as.character(1:ncol(zone.pca.x))))
 #summary(zone.pca)$importance[3,]
forest.new <- cbind(forest.new, zone.pca.x[,1:6]) #99.7% of importantance

par(mfrow=c(1,2))
plot(summary(soil.pca)$importance[3,], xlab="Principal Components", ylab="Importance",
     main="Soil Type PCA Importance Plot", pch=20, col="red")
plot(summary(zone.pca)$importance[3,], xlab="Principal Components", ylab="Importance",
     main="Soil Zone PCA Importance Plot", pch=20, col="blue")
par(mfrow=c(1,1))

#rm(list = c(temp.soil, temp.zone))

```


The correlation plot below also shows high correlations between Hillshade, Aspect, and Slope. By performing PCA analysis we are able to reduce 5 variables down to 3, with 0 correlation and explaining 99.7% of the variance. This is highly likely to be useful for models that need to minimize highly correlated variables.

```{r setup data 4, fig.cap="PCA Correlation", fig.height=4}

idxs = grep("Aspect|Hillshade|Slope", colnames(forest.numeric))
temp = forest.new[,idxs]
shadeslope.pca = prcomp(temp, scale = F)
shadeslope.pca.x = shadeslope.pca$x
colnames(shadeslope.pca.x) = c('shade.pca.pc1','shade.pca.pc2','shade.pca.pc3','shade.pca.pc4','shade.pca.pc5')
forest.new <- cbind(forest.new, shadeslope.pca.x[,1:3]) #99.7% of important
#plot(summary(shadeslope.pca)$importance[3,])
#summary(shadeslope.pca)$importance[3,]
#summary(shadeslope.pca)

idxs = grep("pca|PC", colnames(forest.new))
corrplot(cor(forest.new[,idxs]), 
         tl.col = "black", tl.cex = 0.8, tl.srt = 45,
         cl.cex = 0.8, pch.cex = 0.8, diag = FALSE,
         type="lower",
         addCoefasPercent = TRUE, addCoef.col = TRUE,number.cex = .6) #Matt added to show correlation amounts


```


Several of the multi-classification models we will rely on accounting for variables with near zero variance. Neural networks, logistic regression and KNN models prefer that no near zero variance variables are in the dataset. In this dataset, 32 of the 40 soil variables have near zero variance. We will look to principal component analysis, combining predictors, and removing predictors to remedy this issue. 

```{r}

#idxs.nzv = nzv(forest.new)
#colnames(forest.new)[idxs.nzv]

```

##Splitting the Data

We have split our data into 70/30 training-testing set so that we could evaluate the performance of our models.

```{r setup data 5}
idxs_trans = grep("trans", colnames(forest.new))
forest.transforms= forest.new[,idxs_trans]
idxs_pca = grep("PC|shade.pca", colnames(forest.new))
forest.pca= forest.new[,idxs_pca]
idxs_buck = grep("buck", colnames(forest.new))
forest.bucketing= forest.new[,idxs_buck]

#Training/Test Splitting
set.seed(330)
fraction.train <- .7 # Enter Training Set Size
fraction.valid <- 1 - fraction.train
size.train <- fraction.train*nrow(forest.new)
size.valid <- nrow(forest.new) - size.train
indices.train <- sort(sample(seq_len(nrow(forest.new)), size=size.train))
indices.valid <- setdiff(seq_len(nrow(forest.new)), indices.train)
forest.train <- forest.new[indices.train,]
forest.valid <- forest.new[indices.valid,]


```

# Exploratory Models - Feature Selection

Next we will run a few exploratory models to help us understand the relationships in our data and help to evaluate the most important variables for feature selection.

## Linear Discriminant Analysis

Linear Discriminant Analysis tries to find a linear combination of the predictors that gives maximum separation between the centers of the data while at the same time minimizing the variation within each group of data. We ran an exploratory model on the data that returned the linear combinations of the original variables that were created to distinguish between the classes. The variables with large absolute values in the scalings are more likely to be influential. For this data, Elevation, Area4 and trans.zone27 seem to be among the important variables. The first discriminant function, LD1, achieves 73.85% of the separation of classes, with the second discriminant function, LD2, improving the separation by 18.19%. Therefore, to achieve a good separation of the classes, we should use both of the first two discriminant functions. 

```{r}
#Remove SoilTypes and Aspect, Slope and Hillsides
forest.train.rm <- forest.train[,-c(2,3,4,7,8,9, 15:54,68:83)]
```


```{r}
forest.train.rm <- forest.train.rm[,-5]
```

```{r}
forest.train.rm$CoverType <- as.factor(forest.train.rm$CoverType)
```


```{r, eval=FALSE, warning=FALSE, error=FALSE}

#explore.lda <- train(CoverType ~ .,  data = forest.train.rm,
                             #method = "lda", 
                             #metric = "Kappa", 
                             #preProc = c("center", "scale"))

```

```{r}
#saveRDS(explore.lda, "./explore.lda.rds")

```

```{r}
explore.lda <- readRDS("./explore.lda.rds")
```


```{r}
kable(explore.lda$finalModel$scaling, format="pandoc")
```


## Decision Tree

The tree plot below shows the result of fitting a decision tree algorithm to all of our data, the purpose of which is to draw insights regarding predictor variables that could be most effective in building a predictive model. Each node in the tree shows the predicted class, the predicted probability of each class and the percentage of observations in the node. Our tree uses the variables Elevation, Trans.zone87 and Area3 to predict our classes.

```{r, fig.cap="Tree Plot", fig.height=4}
library(rpart)
library(rpart.plot)
rpart.plot(rpart(factor(forest.train.rm$CoverType) ~ ., data = forest.train.rm), main = "Tree Plot for Cover Type")
```

```{r, eval=FALSE}
library(randomForest)
set.seed(123)
explore.rf <- randomForest(CoverType~.,
                         data = forest.train.rm,
                         ntree = 10, nodesize = 10, importance = TRUE)
```

```{r}
#saveRDS(explore.rf, "./explore.rf.rds")

```

```{r}
explore.rf <- readRDS("./explore.rf.rds")
```

## Random Forest

The chart below shows the variables plotted by two measures of importance, Mean Decrease Accuracy and Mean Decrease Gini. Gini importance measures the average gain of purity by splits of a given variable.

```{r, fig.cap="Variable Importance", warning=FALSE, message=FALSE, fig.height=4}
library(randomForest)
varImpPlot(explore.rf, main = 'Variable Importance', cex = 0.5,pch=19, col=1)
```


```{r setup all data, eval=FALSE, echo=FALSE, message=F, error=F, warning=F}

# read in the data, create dataframe
gz = gzfile('data/covtype.data.gz','rt') 
forest.orig = read.csv(gz,header=F)
forest.orig.colnames = t(read.csv('data/covtyp.colnames.csv',header=F))
colnames(forest.orig) = forest.orig.colnames
forest.var.continuous = c('Elevation','Aspect','Slope', 'HDist.Hydrology', 'VDist.Hydrology', 
                          'HDist.Roadway', 'Hillshade.9am', 'Hillshade.12pm', 'Hillshade.3pm',
                          'HDist.FirePoint')
library(lattice)
library(ggplot2)
library(corrplot)
library(MASS)
library(caret)
library(car)
library(DMwR)
library(dplyr)
library(doMC)
library(randomForest)
library(nnet)
library(neuralnet)
registerDoMC(cores = 5)

forest.new= forest.orig
forest.new$trans.LDist.Hydrology <- sqrt(forest.new$VDist.Hydrology^2 + forest.new$HDist.Hydrology^2) 

forest.new$trans.zone27 <- rowSums(forest.new[,c("SoilType1", "SoilType2","SoilType3","SoilType4", "SoilType5","SoilType6")])
forest.new$trans.zone35 <- rowSums(forest.new[,c("SoilType7", "SoilType8")])
forest.new$trans.zone42 <- forest.new$SoilType9
forest.new$trans.zone47 <- rowSums(forest.new[,c("SoilType10", "SoilType11","SoilType12","SoilType13")])
forest.new$trans.zone51 <- rowSums(forest.new[,c("SoilType14", "SoilType15")])
forest.new$trans.zone61 <- rowSums(forest.new[,c("SoilType16", "SoilType17")])
forest.new$trans.zone67 <- forest.new$SoilType18
forest.new$trans.zone71 <- rowSums(forest.new[,c("SoilType19", "SoilType20","SoilType21")])
forest.new$trans.zone72 <- rowSums(forest.new[,c("SoilType22", "SoilType23")])
forest.new$trans.zone77 <- rowSums(forest.new[,c("SoilType24", "SoilType25","SoilType26","SoilType27", 
                                                 "SoilType28", "SoilType29", "SoilType30","SoilType31",
                                                 "SoilType32", "SoilType33", "SoilType34")])
forest.new$trans.zone87 <- rowSums(forest.new[,c("SoilType35", "SoilType36","SoilType37","SoilType38",
                                                 "SoilType39","SoilType40")])

set.seed(444)
idxs.soil = grep("Soil", colnames(forest.new))
temp.soil = forest.new[,idxs.soil]
soil.pca = prcomp(temp.soil, scale = F)
soil.pca.x = soil.pca$x
colnames(soil.pca.x) <- c(paste0("soil.pca.pc",as.character(1:ncol(soil.pca.x))))
forest.new <- cbind(forest.new, soil.pca.x[,1:16]) #90.7% of importantance
idxs.zone = grep("trans.zone", colnames(forest.new))
temp.zone = forest.new[,idxs.zone]
zone.pca = prcomp(temp.zone, scale = F)
zone.pca.x = zone.pca$x
colnames(zone.pca.x) <- c(paste0("zone.pca.pc",as.character(1:ncol(zone.pca.x))))
forest.new <- cbind(forest.new, zone.pca.x[,1:6]) #99.7% of importantance
rm(list = c('temp.soil', 'temp.zone'))

idxs = grep("Aspect|Hillshade|Slope", colnames(forest.new))
temp = forest.new[,idxs]
shadeslope.pca = prcomp(temp, scale = F)
shadeslope.pca.x = shadeslope.pca$x
colnames(shadeslope.pca.x) = c('shade.pca.pc1','shade.pca.pc2','shade.pca.pc3','shade.pca.pc4','shade.pca.pc5')
forest.new <- cbind(forest.new, shadeslope.pca.x[,1:3]) #99.7% of important

idxs_trans = grep("trans", colnames(forest.new))
forest.transforms= forest.new[,idxs_trans]
idxs_pca = grep("PC|shade.pca", colnames(forest.new))
forest.pca= forest.new[,idxs_pca]
#idxs_buck = grep("buck", colnames(forest.new))
#forest.bucketing= forest[,idxs_buck]

rm(list = c('temp.soil', 'temp.zone', 'forest.pca', 'forest.transforms', 'shadeslope.pca.x',
            'forest.bucketing', 'soil.pca.x', 'temp', 'zone.pca.x', 'forest', 'forest.numeric',
            'forest.pca', 'idxs_pca', 'idxs_buck', 'idxs_trans', 'idxs.soil', 'idxs.zone',
            'shadeslope.pca', 'soil.pca', 'zone.pca', 'gz'))

```


```{r modeling setup}

forest.model = forest.new

### update forest.new with any renames or consolidations
# rename some predictors
forest.model.colnames = colnames(forest.model)
idxs = grep("^PC",forest.model.colnames)
forest.model.colnames[idxs] = paste("pca.soil.",forest.model.colnames[idxs],sep = "")
colnames(forest.model) = forest.model.colnames

# convert 4 area predictors to one factor variable
idxs = grep("^Area",colnames(forest.model))
mat = as.matrix(forest.model[,idxs])
forest.model$forest.area = factor(mat%*%(1:ncol(mat)), labels = colnames(mat)) 
mat = NULL
forest.model[,idxs] = NULL

# convert zones into one factor variable
idxs = grep("trans.zone",colnames(forest.model))
mat = as.matrix(forest.model[,idxs])
forest.model$forest.zone = factor(mat%*%(1:ncol(mat)), labels = colnames(mat)) 
mat = NULL
forest.model[,idxs] = NULL

# convert to factors where needed
idxs = grep("Area|SoilType|CoverType|trans.zone",colnames(forest.model))
forest.model[,idxs] = lapply(forest.model[,idxs], as.factor)

#Training/Test Splitting
set.seed(330)
fraction.train = .7 # Enter Training Set Size
fraction.valid = 1 - fraction.train
size.train = fraction.train*nrow(forest.model)
size.valid = nrow(forest.model) - size.train
indices.train = sort(sample(seq_len(nrow(forest.model)), size=size.train))
indices.valid = setdiff(seq_len(nrow(forest.model)), indices.train)

# create a couple versions of the model to try out with the algorithms
forest.model1 = forest.model # bare bones model without Soil anything
forest.model2 = forest.model # bare bones model with Soil pca

# remove the unwanted variables for modeling
idxs = grep("^SoilType|^Aspect|^Hillshade|^Slope|^HDist.Hydrology|VDist.Hydrology|soil.pca|zone.pca",colnames(forest.model))
forest.model1[,idxs] = NULL

idxs = grep("^Aspect|^Hillshade|^Slope|^HDist.Hydrology|VDist.Hydrology|^SoilType|zone.pca",colnames(forest.model))
forest.model2[,idxs] = NULL

forest.train1 = forest.model1[indices.train,]
forest.valid1 = forest.model1[indices.valid,]

forest.train2 = forest.model2[indices.train,]
forest.valid2 = forest.model2[indices.valid,]

# model that makes sure the low model types are always present in a sample
set.seed(444)
sample4.tbl = table(forest.model2$CoverType)
forest.model4 = sample_n(forest.model2[forest.model2$CoverType==4,], 1917)
for (i in 1:7) {
  cnt = sample4.tbl[i]
  if (cnt > 100000) {
    forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],20000))
  } else if (cnt > 10000) {
    forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],5000))
  } else if (cnt > 3000) {
    forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],3000))
  }
}
forest.train4 = forest.model4
forest.valid4 = forest.model2[indices.valid,]


rm(list = c('indices.train', 'indices.valid', 'size.train', 'size.valid'))

```

\newpage

```{r sampling, eval=FALSE}

### Check if sampling technqiues will improve accuracy

# percentage by class before sampling
forest.train.proptable = round(prop.table(table(forest.train$CoverType)), digits = 3)
forest.train.proptable

# train set 1: downsample all classes to lowest observation class count. 
# 1,917 each, 13,300 total
set.seed(444)
forest.sample1 = as.data.frame(forest.train %>% group_by(CoverType) %>% sample_n(size = 1917))
sample1.forest = randomForest(CoverType~.,data=forest.sample1,importance=TRUE)
sample1.pred = caret::predict(sample1.forest, newdata = forest.valid)
sample1.cm = confusionMatrix(sample1.pred,forest.valid$CoverType) 
sample1.cm$overall[2]
rm(list = c('forest.sample1','sample1.forest','sample1.pred'))

# random sample of 13,300
set.seed(444)
sample2.forest = randomForest(CoverType~.,data=sample_n(forest.train,13300),importance=TRUE)
sample2.pred = predict(sample2.forest, newdata = forest.valid)
sample2.cm = confusionMatrix(sample2.pred, forest.valid$CoverType) 
sample2.cm$overall[2]
rm(list = c('sample2.forest','sample2.pred'))


# 5000 of each class with replacement
set.seed(444)
forest.sample3 = as.data.frame(forest.train %>% group_by(CoverType) %>% sample_n(size = 5000,replace=TRUE))
sample3.forest = randomForest(CoverType~.,data=forest.sample3,importance=TRUE)
sample3.pred = predict(sample3.forest, newdata = forest.valid)
sample3.cm = confusionMatrix(sample3.pred, forest.valid$CoverType) 
sample3.cm$overall[2]
rm(list = c('forest.sample3','sample3.forest','sample3.pred'))


# tiered selection of samples based on category
sample4.tbl = table(forest.train$CoverType)
forest.sample4 = sample_n(forest.train[forest.train$CoverType==4,], 1917)
for (i in 1:7) {
  cnt = sample4.tbl[i]
  if (cnt > 100000) {
    forest.sample4 = rbind(forest.sample4, sample_n(forest.train[forest.train$CoverType==i,],20000))
  } else if (cnt > 10000) {
    forest.sample4 = rbind(forest.sample4, sample_n(forest.train[forest.train$CoverType==i,],5000))
  } else if (cnt > 3000) {
    forest.sample4 = rbind(forest.sample4, sample_n(forest.train[forest.train$CoverType==i,],3000))
  }
}
sample4.forest = randomForest(CoverType~., data=forest.sample4, importance=TRUE)
sample4.pred = predict(sample4.forest, newdata = forest.valid)
sample4.cm = confusionMatrix(sample4.pred, forest.valid$CoverType) 
sample4.cm$overall[2]
rm(list = c('sample4.tbl','forest.sample4','sample4.forest','sample4.pred'))


# random sample of 39,917
set.seed(444)
#sample5.forest = randomForest(CoverType~., data=sample_n(forest.train, 39917), importance=TRUE)
sample5.forest = randomForest(CoverType~., data=sample_n(forest.train, 40000), importance=TRUE)
sample5.pred = predict(sample5.forest, newdata = forest.valid)
sample5.cm = confusionMatrix(sample5.pred, forest.valid$CoverType) 
sample5.cm$overall[2]


sample.types = c('Sample1','Sample2','Sample3','Sample4','Sample5')
sample.results = c(sample1.cm$overall[2],sample2.cm$overall[2],sample3.cm$overall[2],
                   sample4.cm$overall[2],sample5.cm$overall[2])
sample.results = c(sample1.cm$overall[1],sample2.cm$overall[1],sample3.cm$overall[1],
                   sample4.cm$overall[1],sample5.cm$overall[1])
cbind(sample.types,sample.results)

# SMOTE sample set
#set.seed(444)
#idxs.row = forest.t$CoverType == 1 | forest.t$CoverType == 2
#forest.t3 = forest.t
#forest.t3$RelativeSize = as.factor(ifelse(idxs.row,'Majority','Minority'))
#m = SMOTE(RelativeSize ~ ., forest.t3, perc.over = 50, perc.under=5)
#table(m$CoverType)
#temp = table(forest.t$CoverType)
#forest.t3 = sample_n(forest.v[forest$CoverType==2,],5000)

# sample of 20,300
#set.seed(444)
#df.rf = randomForest(CoverType~.,data=sample_n(forest.t,20300),importance=TRUE)
#pred = predict(df.rf, newdata = forest.v)
#confusionMatrix(pred,forest.v$CoverType) # kappa 0.7179

```

```{r, eval=FALSE}
m = sample4.cm$table
ms = apply(m,2,sum)
mss = round(apply(m,1,function(x) {return (x/ms)}),2)
mss

corrplot(mss, 
         tl.col = "black", 
         tl.cex = 0.8, 
         tl.srt = 0,
         cl.cex = 0.8,
         pch.cex = 0.8, 
         diag = TRUE,
         type="full",
         addCoefasPercent = TRUE, 
         addCoef.col = TRUE,
         number.cex = .6) #Matt added to show correlation amounts

```

\newpage
# Modeling Plan

Based on our modeling problem and exploratory data analysis, we will run various classification algorithms that can predict more than two classes. We will try variations of the following algorithms, which will require different data preparations.

## Samples

In order to perform an initial analysis of the various models, we will use a sample of the training data. Once we have honed in on the correct tuning parameters for the models, we will run the models against the full dataset. This is an important step towards making the modeling process perform faster.

To accomplish this, we attempted the following samples:

1. 1900 observations from each class
2. random sample of 13,000
3. 5000 observations from each class with replacement
4. a tiered selection of observations, using all observations from low volume types, and using a higher sampling from the more popular types
5. a random sampling of 40,000
6. Stratified sample of 23,000
7. Stratified sample of 46,000

##Neural Network
Rather than having one neuron in the output layer, have N binary neuron leading to multiclass classification. Classes are converted into binary indicators for N binary neurons. Tuning parameters are size and decay. The model is sensitive to highly correlated predictors and near-zero predictors. The data must also be centered and scaled.

For modeling with a neural network, there are several variations that can impact the effectiveness of the model. These include the learning rate, the number of layers in the neural network, and the number of nodes in each layer. Several models were investigated changing these parameters. Additionally, we attempted to use different variables in the modeling. To help narrow in on the appropriate settings, we used cross validation techniques and a tuning grid. 

* 5 nodes, 1 layer, 0.01 learning rate, no soil predictors, random sample -> Kappa 0.56, Accuracy 0.73
* 5 nodes, 1 layer, 0.01 learning rate, soil predictors, random sample -> Kappa 0.57, Accurarcy 0.74
* 9 nodes, 1 layer, 0.01 learning rate, soil predictors, random sample -> Kappa 0.59, Accuracy 0.75
* 15 nodes, 1 layer, 0.05 learning rate, soil predictors, tiered sample -> Kappa 0.66, Accuracy 0.74

The winning neural network model is the one with the highest Kappa with the tiered sampling. This lead to 15 nodes, 1 layer, and a learning rate of 0.05.


```{r neural network, fig.height=4, fig.cap="F1 for Neural Network"}
library(nnet)

build = FALSE

## NN1 ##########################################
# model without soil info, 5 nodes, 0.01 decay
set.seed(444)
forest.model.nn1 = sample_n(forest.train1, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn1))
forest.model.nn1[,idxs] = scale(forest.model.nn1[,idxs], center = TRUE, scale = TRUE)

if (build) {
  forest.nn1 = nnet(CoverType ~ . , data=forest.model.nn1, linout=FALSE, size=5, maxit=2000, decay=0.01, trace=FALSE)
  saveRDS(forest.nn1, "./forest.nn1")
} else {
  forest.nn1 = readRDS("./forest.nn1")
}

idx = grep("CoverType", colnames(forest.valid1))
forest.model.nn1.valid = forest.valid1[,-idx]
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn1.valid))
forest.model.nn1.valid[,idxs] = scale(forest.model.nn1.valid[,idxs], center = TRUE, scale = TRUE)
forest.nn1.pred = predict(forest.nn1, newdata=forest.model.nn1.valid, type="class")
forest.nn1.cm = caret::confusionMatrix(forest.nn1.pred, reference=forest.valid1$CoverType)
forest.nn1.kappa = forest.nn1.cm$overall[2]
forest.nn1.accuracy = forest.nn1.cm$overall[1]

## NN2 ##########################################
#forest.model.nn2 = sample_n(forest.train2, 40000)
#n = names(forest.train2)
#f = as.formula(paste("CoverType ~", paste(n[!n %in% "CoverType"], collapse = " + ")))
#forest.nn2 = pcaNNet(f, forest.model.nn2, size = 5, linout = FALSE, trace = FALSE)

#model with soil info, 5 nodes, 0.01 decay
set.seed(444)
forest.model.nn2 = sample_n(forest.train2, 40000)

if (build) {
  forest.nn2 = nnet(CoverType ~ . , data=forest.model.nn2, linout=FALSE, size=5, maxit=2000, decay=0.01, trace=FALSE)
  saveRDS(forest.nn2, "./forest.nn2")
} else {
  forest.nn2 = readRDS("./forest.nn2")
}

idx = grep("CoverType", colnames(forest.valid2))
forest.nn2.pred = predict(forest.nn2, newdata=forest.valid2[,-idx], type="class")
forest.nn2.cm = caret::confusionMatrix(data=forest.nn2.pred, reference=forest.valid2$CoverType)
forest.nn2.kappa = forest.nn2.cm$overall[2]
forest.nn2.accuracy = forest.nn2.cm$overall[1]

## NN3 ##########################################
#model with soil info, 9 nodes, 0.01 decay
set.seed(444)
forest.model.nn3 = sample_n(forest.train2, 40000)

if (build) {
  forest.nn3 = nnet(CoverType ~ . , data=forest.model.nn3, linout=FALSE, size=9, maxit=2000, decay=0.01, trace=FALSE)
  saveRDS(forest.nn2, "./forest.nn3")
} else {
  forest.nn3 = readRDS("./forest.nn3")
}

idx = grep("CoverType", colnames(forest.valid2))
forest.nn3.pred = predict(forest.nn3, newdata=forest.valid2[,-idx], type="class")
forest.nn3.cm = caret::confusionMatrix(data=forest.nn3.pred, reference=forest.valid2$CoverType)
forest.nn3.kappa = forest.nn3.cm$overall[2]
forest.nn3.accuracy = forest.nn3.cm$overall[1]


## NN4 ##########################################
#### try with cross validation on soil info set

forest.model.nn4 = forest.train4

# when playing reduce the training set so it'll run faster
playing = FALSE
if (playing) {
  build = TRUE
  idxs = which(as.numeric(forest.model.nn4$CoverType)>2, arr.ind = TRUE)
  temp = sample_n(forest.model.nn4[idxs,], 500)  
  idxs = which(as.numeric(forest.model.nn4$CoverType)<=2, arr.ind = TRUE)
  temp = rbind(temp,sample_n(forest.model.nn4[idxs,], 2000))
  forest.model.nn4 = temp
}

if (build) {
  forest.model.nn4$CoverType = paste0("CoverType",forest.model.nn4$CoverType,sep="")
  forest.model.nn4$CoverType = as.factor(forest.model.nn4$CoverType)
  ctrl = trainControl(method = "cv", number = 10, savePredictions = TRUE, classProbs = TRUE)
  tuneGrid=expand.grid(size=c(9,15,19), decay=c(0.01,0.025,0.05))
  forest.nn4 = train(CoverType ~ .,  
                    data=forest.model.nn4, 
                    #preProcess = c('center','scale'),
                    method="nnet", 
                    trControl = ctrl,
                    tuneGrid = tuneGrid,
                    linout = FALSE,
                    maxit=2000
                    )
  saveRDS(forest.nn4, "./forest.nn4")
} else {
  forest.nn4 = readRDS("./forest.nn4")
}

forest.model.nn4.valid = forest.valid4
idx = grep("CoverType", colnames(forest.valid4))
forest.model.nn4.valid = forest.model.nn4.valid[,-idx]
# need to break out factors to columns
#idxs = grep("forest.zone", colnames(forest.nn4.model))
m = dummyVars(" ~ .", data = forest.model.nn4.valid)
m = predict(m, newdata = forest.model.nn4.valid)
# remove one each of the factor predictors, but leave all of the CoverType factors
n = colnames(m)
idxs = grep("forest.area.Area1|forest.zone.trans.zone27", n)
m = m[,-idxs]
colnames(m) = gsub("area.Area","areaArea",colnames(m))
colnames(m) = gsub("zone.trans","zonetrans",colnames(m))

forest.nn4.pred = predict(forest.nn4$finalModel, newdata=m, type="class")
#table(forest.nn4.pred)
forest.nn4.pred = gsub("CoverType","",forest.nn4.pred)

forest.nn4.cm = caret::confusionMatrix(data=forest.nn4.pred, reference=forest.valid4$CoverType)
forest.nn4.kappa = forest.nn4.cm$overall[2]
forest.nn4.accuracy = forest.nn4.cm$overall[1]

#table(forest.nn4.pred)
#forest.nn4.kappa


## NN5 ##########################################
############################################################
#model with soil info and assured low class observations with all training
#data using best result from CV analysis on smaller training data set
#15 nodes, 0.05 decay
set.seed(444)
forest.model.nn5 = forest.train4

#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn5))
#forest.model.nn5[,idxs] = scale(forest.model.nn5[,idxs], center = TRUE, scale = TRUE)
if (build) {
  forest.nn5 = nnet(CoverType ~ . , data=forest.model.nn5, linout=FALSE, size=15, maxit=2000, decay=0.05, trace=FALSE)
  saveRDS(forest.nn5, "./forest.nn5")
} else {
  forest.nn5 = readRDS("./forest.nn5")
}
forest.model.nn5.valid = forest.valid4
idx = grep("CoverType", colnames(forest.valid4))
forest.model.nn5.valid = forest.model.nn5.valid[,-idx]
#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn5.valid))
#forest.model.nn5.valid[,idxs] = scale(forest.model.nn5.valid[,idxs], center = TRUE, scale = TRUE)
forest.nn5.pred = predict(forest.nn5, newdata=forest.model.nn5.valid, type="class")
forest.nn5.cm = caret::confusionMatrix(data=forest.nn5.pred, reference=forest.valid4$CoverType)
forest.nn5.kappa = forest.nn5.cm$overall[2]
forest.nn5.accuracy = forest.nn5.cm$overall[1]

#table(forest.nn5.pred)
#forest.nn5.kappa


## NN6 ##########################################
#model with soil info, two layer (5,2) nodes, 0.01 decay
library(neuralnet)
set.seed(444)
forest.nn6.model = forest.train4
#forest.nn5.model = forest.nn5.model[1:1000,]
idxs = grep("forest.zone", colnames(forest.nn6.model))
m = dummyVars(" ~ .", data = forest.nn6.model[,-idxs])
m = predict(m, newdata = forest.nn6.model)
# remove one each of the factor predictors, but leave all of the CoverType factors
n = colnames(m)
idxs = grep("forest.area.Area1", n)
m = m[,-idxs]
n = colnames(m)
left = paste(n[grep("CoverType",n)], collapse = " + ")
right = paste(n[-grep("CoverType",n)], collapse = " + ")
fnn = as.formula(paste(left, right, sep = " ~ "))

if (build) {
  #forest.nn6 = neuralnet(fnn, data=m, hidden=c(15,9), linear.output=FALSE, learningrate = 0.5)
  #saveRDS(forest.nn6, "./forest.nn6")
} else {
  #forest.nn6 = readRDS("./forest.nn6")
}

#idxs = grep("forest.zone", colnames(forest.valid4))
#m.test = dummyVars(" ~ .", data = forest.valid4[,-idxs])
#m.test = predict(m.test, newdata = forest.valid4)
#n = colnames(m.test)
#idxs = grep("forest.area.Area1|CoverType", n)
#m.test = m.test[,-idxs]
#forest.nn5.pred = neuralnet::compute(forest.nn5, m.test)$net.result
#head(forest.nn5.pred)

#s = apply(forest.nn5.pred,1,function(x){
#  return(which.is.max(x))
  #return(which(x == max(x), arr.ind = TRUE))
#})


############################################################

set.seed(444)
forest.model.nn7 = forest.train4

#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn7))
#forest.model.nn7[,idxs] = scale(forest.model.nn7[,idxs], center = TRUE, scale = TRUE)
if (build) {
  forest.model.nn7$Y = class.ind(forest.model.nn7$CoverType)
  # delete the old target variable
  forest.model.nn7$CoverType=NULL
  forest.nn7 = nnet(Y ~ . , data=forest.model.nn7, linout=FALSE, size=15, maxit=2000, decay=0.05, trace=FALSE, softmax=TRUE)
  saveRDS(forest.nn7, "./forest.nn7")
} else {
  forest.nn7 = readRDS("./forest.nn7")
}
forest.model.nn7.valid = forest.valid4
idx = grep("CoverType", colnames(forest.valid4))
forest.model.nn7.valid = forest.model.nn7.valid[,-idx]
#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn7.valid))
#forest.model.nn7.valid[,idxs] = scale(forest.model.nn7.valid[,idxs], center = TRUE, scale = TRUE)
forest.nn7.pred = predict(forest.nn7, newdata=forest.model.nn7.valid, type="class")
forest.nn7.cm = caret::confusionMatrix(data=forest.nn7.pred, reference=forest.valid4$CoverType)
forest.nn7.kappa = forest.nn7.cm$overall[2]
forest.nn7.accuracy = forest.nn7.cm$overall[1]

```

```{r}
### add code for the best nn performer's accuracy, kappa, f1, and boxplot of f1
#barplot(forest.nn1.cm$byClass[,7])

f1 <- as.data.frame(forest.nn5.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
```


```{r, fig.height=4, fig.cap="Balanced Accuracy for Neural Network"}
ba <- as.data.frame(forest.nn1.cm$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy )) +
  geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
```

\newpage
## Random Forests
Each tree in the forest casts a vote for the classification of a new sample, and the proportion of votes in each class across the ensemble is the predicted probability vector.  Tuning parameter is mtry, the number of variables randomly sampled as candidates at each split. There is no need to preprocess the data. 

### Random Forest - Reduced Feature Set,  Stratified Sample, 5-fold cross-validation and 3 repeats, random search for mtry

#### Sample

For our first Random Forest model, we used a stratified sample of 23,243 observations for training. This amounted to 5% of the observation left after removing 20% of total observation for use in backwards recursive feature selection. Stratified sampling maintains the class distribution found in the original data set. 

```{r}
forest.4 <- readRDS("forest.4.rds")
set.seed(456)
intrain2<-createDataPartition(y=forest.4$CoverType,p=0.05,list=FALSE)
forest.4.train<-forest.4[intrain2,]
forest.4.test<-forest.4[-intrain2,]
```


#### Predictors

Our original data set was augmented with variables suggested by our exploratory data analysis, including linear distance variable was also created using the vertical and horizontal distance to hydrology variables and interactions between our Areas and Elevation, as suggested by the distinct distributions of the areas by elevation. We used recursive backwards feature selection on 20% of our full data set with 'Kappa' set as our metric to maximize. The algorithm is configured to explore all possible subsets of the attributes. It returned 16 predictors.

```{r}
set.seed(7)

# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
# run the RFE algorithm - Backwards Feature Selection with Kappa as metric

#results <- rfe(CoverType ~ ., data = forest.3, metric = "Kappa", rfeControl=control)

#saveRDS(results, "./results.rfe.rds")
results <- readRDS("results.rfe.rds")
# summarize the results
#print(results)
# list the chosen features
rfe.predictors <- predictors(results)
# plot the results
plot(results, type=c("g", "o"))

```
```{r}
rfe.pred <- data.frame(rfe.predictors)
kable(rfe.pred, caption= "RFE Predictors", format="pandoc")
```

#### Tuning Methodology

In order to get better accuracy from our algorithm we used algorithm tuning to find the best parameter value for our problem. We used random search strategy to try random values within a range. Kappa was used to select the optimal model using the largest value. The final value used for the model was mtry = 10. 

```{r}
control <- trainControl(method="repeatedcv", number=5, repeats=3, search = "random")
metric <- "Kappa"
set.seed(345)
mtry <- sqrt(ncol(forest.4.train))
#rf.mod1 <- train(CoverType~ Elevation + HDist.FirePoint + HDist.Roadway + trans.LDist.Hydrology +
#+  VDist.Hydrology + Hillshade.3pm + Hillshade.12pm + Aspect +   
#+  HDist.Hydrology + interElAr3 + Slope + interElAr1 + SoilType22 +
#+  SoilType23 + SoilType2 + SoilType33, data=forest.4.train, method="rf", 
#+ metric=metric,tuneLength=15, trControl=control)

rf.mod1 <- readRDS("rf.mod1.rds")

plot(rf.mod1)
```

#### Results

```{r}
pred.rf1 = predict(rf.mod1$finalModel, newdata=forest.4.test )
cm.rf1 = confusionMatrix(data=pred.rf1, forest.4.test$CoverType)
```

```{r}
library(pander)
pander(cm.rf1$table)
```

```{r}
#cm.rf1
```

The model had an accuracy of 85.1%, but accuracy is not a good measurement for our imbalanced data set since it reflects the underlying class distributions. We will use alternative metrics such as Kappa, Balanced Accuracy, and F1 score to evaluate our models. Our model achived a Kappa value of 75.7 and had poor results in our underrepresented classes.

```{r, fig.height=4, fig.cap="F1 for Random Forest Model #1"}
f1 <- as.data.frame(cm.rf1$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")

```

```{r, fig.height=4, fig.cap="Balanced Accuracy for Random Forest Model #1"}
ba <- as.data.frame(cm.rf1$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
```


\newpage
### Random Forest - PCA Soil,  Stratified Sample, 5-fold cross-validation and 3 repeats, Grid search for mtry

#### Sample

For our second Random Forest model, we used the stratified sample of 46,484 observations for training. 

#### Predictors

For our second Random Forest model we removed the 40 soil values and replaced them with 16 variables that explained 90% of the variance.

```{r}
set.seed(444)
idxs.soil = grep("Soil", colnames(forest.4))
temp.soil = forest.4[,idxs.soil]
soil.pca = prcomp(temp.soil, scale = F)
soil.pca.x = soil.pca$x
colnames(soil.pca.x) <- c(paste0("soil.pca.pc",as.character(1:ncol(soil.pca.x))))

forest.4 <- cbind(forest.4, soil.pca.x[,1:16]) #90.7% of importantance

set.seed(456)
intrain3<-createDataPartition(y=forest.4$CoverType,p=0.1,list=FALSE)
forest.4.train1<-forest.4[intrain3,]
forest.4.test1<-forest.4[-intrain3,]

```


#### Tuning Methodology

We used grid search strategy to try random values within a range. Each axis of the grid is an algorithm parameter, and points in the grid are specific combinations of parameters. Because we are only tuning one parameter, the grid search is a linear search through a vector of candidate values. Kappa was used to select the optimal model using the largest value. The final value used for the model was mtry = 15. 

```{r}
control <- trainControl(method="repeatedcv", number=5, repeats=3, search="grid")
set.seed(456)
tunegrid <- expand.grid(.mtry=c(1:15))
#rf_gridsearch <- train(CoverType ~ Elevation + Aspect + Slope + HDist.Hydrology +  
     #               + VDist.Hydrology + HDist.Roadway + Hillshade.9am + Hillshade.12pm  
      #              + Hillshade.3pm + HDist.FirePoint + Area1 + Area2 
     #               + Area3+ Area4 + trans.LDist.Hydrology + interElAr1 + interElAr2 
     #               + interElAr3 + interElAr4 + below.water + soil.pca.pc1 + soil.pca.pc2
     #               + soil.pca.pc3 + soil.pca.pc4 +  soil.pca.pc5 + soil.pca.pc6 + soil.pca.pc7
     #               + soil.pca.pc8 + soil.pca.pc9+  soil.pca.pc10+ soil.pca.pc11
     #               + soil.pca.pc12 + soil.pca.pc13+ soil.pca.pc14+ soil.pca.pc15
     #               + soil.pca.pc16, 
     #               data=forest.4.train1, method="rf", metric="Kappa", tuneGrid=tunegrid, trControl=control)
#saveRDS(rf_gridsearch, "./rf_gridsearch.rds")

rf_gridsearch <- readRDS("rf_gridsearch.rds")

plot(rf_gridsearch)


```

#### Results

```{r}
pred.rf2 = predict(rf_gridsearch$finalModel, newdata=forest.4.test1 )
cm.rf2 = confusionMatrix(data=pred.rf2, forest.4.test1$CoverType)
```

```{r}
library(pander)
pander(cm.rf2$table)
```

```{r}
#cm.rf2
```

The model had an accuracy of 90.8%, achieved a Kappa value of 85.1% and had much improved results in our underrepresented classes.

```{r, fig.height=4, fig.cap="F1 for Random Forest Model #2"}
f1 <- as.data.frame(cm.rf2$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")

```

```{r, fig.height=4, fig.cap="Balanced Accuracy for Random Forest Model #2"}
ba <- as.data.frame(cm.rf2$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
```


\newpage
##Linear Discriminant Analysis 

LDA assumes normal predictors and that the predictors have equal variance. LDA then estiamtes the mean and variance for the predictors for each class. There is no tuning parameter and the model is sensitive to highly correlated predictors and near-zero predictors. The data must also be centered and scaled.

```{r, eval=FALSE, warning=FALSE, error=FALSE}
set.seed(444)
forest.model.lda1 = forest.train4
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.lda1))
forest.model.lda1[,idxs] = scale(forest.model.lda1[,idxs], center = TRUE, scale = TRUE)



#forest.lda1 <- train(CoverType ~ .,  data = forest.model.lda1,
                             method = "lda", 
                             metric = "Kappa", 
                             preProc = c("center", "scale"))

```

```{r}
#saveRDS(forest.lda1, "./forest.lda1.rds")

```

```{r}
forest.lda1 <- readRDS("./forest.lda1.rds")
```

```{r}
forest.model.lda1.valid = forest.valid4
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.lda1.valid))
forest.model.lda1.valid[,idxs] = scale(forest.model.lda1.valid[,idxs], center = TRUE, scale = TRUE)


pred.lda1 = predict(forest.lda1, newdata=forest.model.lda1.valid)
forest.lda1.cm = confusionMatrix(data=pred.lda1, forest.model.lda1.valid$CoverType)
forest.lda1.kappa = forest.lda1.cm$overall[2]
forest.lda1.accuracy = forest.lda1.cm$overall[1]

```

A matrix of predicted cover types below shoes how well LDA classified cover types. The LDA model had an accuracy of 61.8%, mis-classifying cover types for several different classes below. The model appeared to have an especially difficult time classifying Type 3.

```{r}
pander(forest.lda1.cm$table)
```

Because accuracy is not a good measurement for our imbalanced data set, we look at a F1 and Balanced Accuracy scores below to evaluate our models. Our model had poor results in our underrepresented classes. Many of the Type 3 cover types were mis-classified as Type 4 or 6.

```{r, fig.height=4, fig.cap="F1 for Linear Discriminant Analysis"}
f1 <- as.data.frame(forest.lda1.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")

```

```{r}
ba <- as.data.frame(forest.lda1.cm$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
```

## K-Nearest Neighbors
Predictions are made for by searching through the entire training set for the K most similar instances and summarizing the most common class for those K instances. KNN is suited for lower dimensional data. We will need to center and scale predictors prior to performing KNN. The model is sensitive to near-zero predictors and the tuning parameter is k.

K Nearest Neighbor (KNN) modeling involves a relatively simple algorithm that classifiers a target variable based on the classification of the “k” nearest neighbors. K is selected using cross-validation to avoid over-fitting. For our model, we used ten-fold cross validation across K values ranging from 2-12. Predictor variables were normalized across a random sample of 40,000 training observations. The best performing model used three Shade PCA variables along with summarized Soil Types in the form of Forest Zones. An optimal “k” value of 9 was elected for this model, which resulted in model that had a 19.1% misclassification rate and Kappa alue of 0.6983.

```{r knn, eval=FALSE}
library(class)
library(caret)
library(knncat)


# temp make training set smaller.
set.seed(444)
forest.train.knn <- na.omit(forest.train4)
forest.valid.knn <- na.omit(forest.valid4)
names(forest.train.knn)

#prep data for centering and scaling by removing qualititative variables
forest.train.x <- forest.train.knn[,-c(4,25,26)]
forest.train.y <- forest.train.knn[,4]
forest.valid.x <- forest.valid.knn[,-c(4,25,26)]
forest.valid.y <- forest.valid.knn[,4]


#normalize and standardize training data
df.mean.train <- apply(forest.train.x, 2, mean)
df.sd.train <- apply(forest.train.x, 2, sd)
df.std.train <- t((t(forest.train.x)-df.mean.train)/df.sd.train) #standardize to have 0 mean and unit sd
#apply(df.std.train, 2, mean) # check zero mean
#apply(df.std.train, 2, sd) # check unit sd


forest.train.knn3 <-df.std.train
forest.train.knn3 <- cbind(df.std.train,
                       forest.train.knn$CoverType, 
                       forest.train.knn$forest.area,
                       forest.train.knn$forest.zone)
colnames(forest.train.knn3)[24] <- "CoverType"
colnames(forest.train.knn3)[25] <- "forest.area"
colnames(forest.train.knn3)[26] <- "forest.zone"
forest.train.knn3 <- as.data.frame(forest.train.knn3)
forest.train.knn3$CoverType <- as.factor(forest.train.knn3$CoverType)
forest.train.knn3$forest.area <- as.factor(forest.train.knn3$forest.area)
forest.train.knn3$forest.zone <- as.factor(forest.train.knn3$forest.zone)


#normalize and standardize validation data
df.mean.valid <- apply(forest.valid.x, 2, mean)
df.sd.valid <- apply(forest.valid.x, 2, sd)
df.std.valid <- t((t(forest.valid.x)-df.mean.valid)/df.sd.valid) #standardize to have 0 mean and unit sd
#apply(df.std.valid, 2, mean) # check zero mean
#apply(df.std.valid, 2, sd) # check unit sd

forest.valid.knn3 <- df.std.valid
forest.valid.knn3 <- cbind(df.std.valid,
                           forest.valid.knn$CoverType, 
                           forest.valid.knn$forest.area,
                           forest.valid.knn$forest.zone)
colnames(forest.valid.knn3)[24] <- "CoverType"
colnames(forest.valid.knn3)[25] <- "forest.area"
colnames(forest.valid.knn3)[26] <- "forest.zone"
forest.valid.knn3 <- as.data.frame(forest.valid.knn3)
forest.valid.knn3$CoverType <- as.factor(forest.valid.knn3$CoverType)
forest.valid.knn3$forest.area <- as.factor(forest.valid.knn3$forest.area)
forest.valid.knn3$forest.zone <- as.factor(forest.valid.knn3$forest.zone)

#table(forest.train.knn3[24])
#table(forest.valid.knn3[24])
#str(forest.train.y[24])

forest.train.knn3.x <- forest.train.knn3[,-c(24)]
forest.train.knn3.y <- forest.train.knn3[24]
forest.valid.knn3.x <- forest.valid.knn3[,-c(24)]
forest.valid.knn3.y <- forest.valid.knn3[24]


#K-Fold Cross Validation
set.seed(1)
idx <- createFolds(forest.train.y , k=10)
#sapply(idx, length)

#head(forest.train.knn[,4])
#head(forest.train.knn3[24])

#Optimize K
ks <- 1:12
res <- sapply(ks, function(k) {
  ##try out each version of k from 1 to 12
  res.k <- sapply(seq_along(idx), function(i) {
    ##loop over each of the 10 cross-validation folds
    ##predict the held-out samples using k nearest neighbors
    knn.pred <- knn(forest.train.knn3.x[-idx[[1]] , ], 
                    forest.valid.knn3.x[ idx[[1]], ], 
                    forest.train.y[-idx[[1]] ], 
                    k = k)
    ##the ratio of misclassified samples
    mean(forest.valid.y[ idx[[i]] ] != knn.pred)
  })
  ##average over the 10 folds
  mean(res.k)
})
#res

df.knn <- knn(forest.train.knn3.x,forest.valid.knn3.x,forest.train.y,k=9)
knn.confusion <- table(df.knn,forest.valid.y[ idx[[1]] ] )
knn.confusion <- table(df.knn,forest.valid.y)

plot(ks, res, type="o",ylab="misclassification error") #K=9
confusionMatrix(knn.confusion)


```



## Logistic Regression

The logistic regressino model is sensitive to highly correlated predictors and near-zero predictors. The data must also be centered and scaled.

```{r}
forest.4 <- readRDS("forest.4b.rds")
set.seed(456)
intrain2<-createDataPartition(y=forest.4$CoverType,p=0.1,list=FALSE)
forest.4.train<-forest.4[intrain2,]
forest.4.test<-forest.4[-intrain2,]
```



```{r, eval=FALSE}
#lr.mod1 <- train(CoverType ~ ., data=forest.4.train, method="multinom")
```



```{r}
#saveRDS(lr.mod1, "lr.mod1.rds")
lr.mod1 <- readRDS("lr.mod1.rds")
```

```{r}
#Predict on Validation Set
pred.lr.mod1 <- predict.train(lr.mod1, newdata = forest.4.test)
xtab <- table(pred.lr.mod1, forest.4.test$CoverType ) 
lr.mod1.cm <- confusionMatrix(xtab)
```

```{r}
#lr.mod1.cm
```


## Support Vector Machine
A support vector machine algorithm an optimal hyperplane which categorizes new examples into a class. The tuning parameter is C, allows violation of the margins with C=0 allowing for no violation and higher variance and larger C resulting in a less sensitive algorithm. the The model requires centering and scaling of data. 


```{r}
library(e1071)
set.seed(444)
forest.model.svm1 = sample_n(forest.train4, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1))
forest.model.svm1[,idxs] = scale(forest.model.svm1[,idxs], center = TRUE, scale = TRUE)

#forest.svm.1 <- svm(CoverType ~ ., method = "class", data = forest.model.svm1)
#forest.svm.1
```

```{r}
#saveRDS(forest.svm.1, "./forest.svm1.rds")
```

```{r}
forest.svm1 <- readRDS("./forest.svm1.rds")
```


```{r}
forest.model.svm1.valid = forest.valid4
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1.valid))
forest.model.svm1.valid[,idxs] = scale(forest.model.svm1.valid[,idxs], center = TRUE, scale = TRUE)


#pred.svm1 = predict(forest.svm.1, newdata=forest.model.svm1.valid)

#saveRDS(pred.svm1, "./pred.svm1.rds")
pred.svm1 <- readRDS("./pred.svm1.rds")

tab.svm <- table("Predicted Class" = pred.svm1, "Actual" = forest.model.svm1.valid$CoverType)
#tab.svm
```

```{r}
forest.svm1.cm <-confusionMatrix(data=pred.svm1, forest.model.svm1.valid$CoverType)
forest.svm1.kappa = forest.svm1.cm$overall[2]
forest.svm1.accuracy = forest.svm1.cm$overall[1]
```

A matrix of predicted cover types below shoes how well the Support Vector Machine model classified cover types. The SVM model had an accuracy of 75.0%, mis-classifying cover types for several different classes below. The model appeared to have an especially difficult time classifying Types 5 and 6.

```{r}
pander(forest.svm1.cm$table)
```

The bar chart below shows that all cover types were predicted by the SVM model. Many of the Type 5 cover types were mis-classified as Type 2 or 3, and Types 5 and 6 were under-represented.

```{r, fig.height=4, fig.cap="F1 for Support Vector Machines"}
f1 <- as.data.frame(forest.svm1.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")

```



```{r}
ba <- as.data.frame(forest.svm1.cm$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
  geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
```

#Model Evaluation

When working with a multiple classification problem, it is important to evaluate a model based on more than just its accuracy. 

```{r}

#add Neural Network models, K Nearest Neighbor and Logistic Regression

models = c("Neural Network- 15 Nodes","Random Forest","Random Forest w PCA", "Linear Discriminant Analysis","Support Vector Machines")

stats = c("Model", "Accuracy", "Kappa")

accuracy = round(c(forest.nn5.accuracy,cm.rf1$overall[1],cm.rf2$overall[1],forest.lda1.accuracy,forest.svm1.accuracy),
digits = 3)

kappa = round(c(forest.nn5.kappa,cm.rf1$overall[2],cm.rf2$overall[2],forest.lda1.kappa,forest.svm1.kappa),
digits = 3)

summary_table = cbind(models,accuracy,kappa)
colnames(summary_table) = stats
rownames(summary_table) = NULL
pander(summary_table, justify = "left")
```



# Conclusion
Our initial analysis for our forest cover type prediction problem included defining our modeling problem, doing a data quality and inventory check and performing a preliminary exploratory data analysis. The results of our data quality check showed that we had no missing data and gave us a cursory understanding of our data set. 


Our preliminary exploratory analysis revealed some potentially useful predictors and helped us to understand the relationships in our data. Principal components analysis helped us narrow our soil variables down from 40 to 16 variables. Additionally, we prepared the data by creating a subset of 70% of the data to train our models on, and a validation set of 30% of the data to test those models on. 

Next we experimented with different samples, feature sets and several classification algorithms and assessed our initial modeling results. Our next step will be to conclude our modeling methods and compare our results.


```{r random forest, eval=FALSE}
library(randomForest)
library(caret)

library(doMC)
registerDoMC(cores = 5)

# temp make training set smaller.
set.seed(444)
forest.train = forest.train[sample(nrow(forest.train), 20000, replace = FALSE),]

# setup
preprocess = c("zv")
control = trainControl(method="cv", number=10)
metric = "Kappa"
set.seed(444)
mtry = floor(sqrt(ncol(forest.train) - 1))
tunegrid = expand.grid(mtry=mtry, ntree=c(500,1000,1500))

idxs = grep("^orig.Elevation|^orig.Aspect|^orig.Slope|^orig|^VDist|^Hillshade|^Area|^SoilType",colnames(forest.train))
form = sapply(colnames(forest.train[,idxs]),function(x) {
  return (paste(x,' + '))
})
form = trimws(paste(unlist(form), collapse=''))
form = trimws(gsub('\\+$','',form))
form = paste('CoverType ~ ',form)
form = as.formula(form)

# model.rf <- train(form, 
#                   data      = forest.train, 
#                   method    = "rf", 
#                   metric    = metric, 
#                   tuneGrid  = tunegrid, 
#                   trControl = control,
#                   preProc   = preprocess)

df.rf = randomForest(CoverType~.,data=forest.train,mtry=9,importance=TRUE)
varImpPlot(df.rf, main='Variable Importance from Random Forest', cex=0.8)

```






```{r logistic regression}

```



```{r ensemble}

```

<!--

=======
>>>>>>> update report with explore models
# Comparison of Results

# Conclusions

# Bibliography

-->
