indices.train = sort(sample(seq_len(nrow(forest.model)), size=size.train))
indices.valid = setdiff(seq_len(nrow(forest.model)), indices.train)
# create a couple versions of the model to try out with the algorithms
forest.model1 = forest.model # bare bones model without Soil anything
forest.model2 = forest.model # bare bones model with Soil pca
# remove the unwanted variables for modeling
idxs = grep("^SoilType|^Aspect|^Hillshade|^Slope|^HDist.Hydrology|VDist.Hydrology|soil.pca|zone.pca",colnames(forest.model))
forest.model1[,idxs] = NULL
idxs = grep("^Aspect|^Hillshade|^Slope|^HDist.Hydrology|VDist.Hydrology|^SoilType|zone.pca",colnames(forest.model))
forest.model2[,idxs] = NULL
forest.train1 = forest.model1[indices.train,]
forest.valid1 = forest.model1[indices.valid,]
forest.train2 = forest.model2[indices.train,]
forest.valid2 = forest.model2[indices.valid,]
# model that makes sure the low model types are always present in a sample
set.seed(444)
sample4.tbl = table(forest.model2$CoverType)
forest.model4 = sample_n(forest.model2[forest.model2$CoverType==4,], 1917)
for (i in 1:7) {
cnt = sample4.tbl[i]
if (cnt > 100000) {
forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],20000))
} else if (cnt > 10000) {
forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],5000))
} else if (cnt > 3000) {
forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],3000))
}
}
forest.train4 = forest.model4
forest.valid4 = forest.model2[indices.valid,]
rm(list = c('indices.train', 'indices.valid', 'size.train', 'size.valid'))
library(nnet)
build = FALSE
## NN1 ##########################################
# model without soil info, 5 nodes, 0.01 decay
set.seed(444)
forest.model.nn1 = sample_n(forest.train1, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn1))
forest.model.nn1[,idxs] = scale(forest.model.nn1[,idxs], center = TRUE, scale = TRUE)
if (build) {
forest.nn1 = nnet(CoverType ~ . , data=forest.model.nn1, linout=FALSE, size=5, maxit=2000, decay=0.01, trace=FALSE)
saveRDS(forest.nn1, "./forest.nn1")
} else {
forest.nn1 = readRDS("./forest.nn1")
}
idx = grep("CoverType", colnames(forest.valid1))
forest.model.nn1.valid = forest.valid1[,-idx]
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn1.valid))
forest.model.nn1.valid[,idxs] = scale(forest.model.nn1.valid[,idxs], center = TRUE, scale = TRUE)
forest.nn1.pred = predict(forest.nn1, newdata=forest.model.nn1.valid, type="class")
forest.nn1.cm = caret::confusionMatrix(forest.nn1.pred, reference=forest.valid1$CoverType)
forest.nn1.kappa = forest.nn1.cm$overall[2]
forest.nn1.accuracy = forest.nn1.cm$overall[1]
## NN2 ##########################################
#forest.model.nn2 = sample_n(forest.train2, 40000)
#n = names(forest.train2)
#f = as.formula(paste("CoverType ~", paste(n[!n %in% "CoverType"], collapse = " + ")))
#forest.nn2 = pcaNNet(f, forest.model.nn2, size = 5, linout = FALSE, trace = FALSE)
#model with soil info, 5 nodes, 0.01 decay
set.seed(444)
forest.model.nn2 = sample_n(forest.train2, 40000)
if (build) {
forest.nn2 = nnet(CoverType ~ . , data=forest.model.nn2, linout=FALSE, size=5, maxit=2000, decay=0.01, trace=FALSE)
saveRDS(forest.nn2, "./forest.nn2")
} else {
forest.nn2 = readRDS("./forest.nn2")
}
idx = grep("CoverType", colnames(forest.valid2))
forest.nn2.pred = predict(forest.nn2, newdata=forest.valid2[,-idx], type="class")
forest.nn2.cm = caret::confusionMatrix(data=forest.nn2.pred, reference=forest.valid2$CoverType)
forest.nn2.kappa = forest.nn2.cm$overall[2]
forest.nn2.accuracy = forest.nn2.cm$overall[1]
## NN3 ##########################################
#model with soil info, 9 nodes, 0.01 decay
set.seed(444)
forest.model.nn3 = sample_n(forest.train2, 40000)
if (build) {
forest.nn3 = nnet(CoverType ~ . , data=forest.model.nn3, linout=FALSE, size=9, maxit=2000, decay=0.01, trace=FALSE)
saveRDS(forest.nn2, "./forest.nn3")
} else {
forest.nn3 = readRDS("./forest.nn3")
}
idx = grep("CoverType", colnames(forest.valid2))
forest.nn3.pred = predict(forest.nn3, newdata=forest.valid2[,-idx], type="class")
forest.nn3.cm = caret::confusionMatrix(data=forest.nn3.pred, reference=forest.valid2$CoverType)
forest.nn3.kappa = forest.nn3.cm$overall[2]
forest.nn3.accuracy = forest.nn3.cm$overall[1]
## NN4 ##########################################
#### try with cross validation on soil info set
forest.model.nn4 = forest.train4
# when playing reduce the training set so it'll run faster
playing = FALSE
if (playing) {
build = TRUE
idxs = which(as.numeric(forest.model.nn4$CoverType)>2, arr.ind = TRUE)
temp = sample_n(forest.model.nn4[idxs,], 500)
idxs = which(as.numeric(forest.model.nn4$CoverType)<=2, arr.ind = TRUE)
temp = rbind(temp,sample_n(forest.model.nn4[idxs,], 2000))
forest.model.nn4 = temp
}
if (build) {
forest.model.nn4$CoverType = paste0("CoverType",forest.model.nn4$CoverType,sep="")
forest.model.nn4$CoverType = as.factor(forest.model.nn4$CoverType)
ctrl = trainControl(method = "cv", number = 10, savePredictions = TRUE, classProbs = TRUE)
tuneGrid=expand.grid(size=c(9,15,19), decay=c(0.01,0.025,0.05))
forest.nn4 = train(CoverType ~ .,
data=forest.model.nn4,
#preProcess = c('center','scale'),
method="nnet",
trControl = ctrl,
tuneGrid = tuneGrid,
linout = FALSE,
maxit=2000
)
saveRDS(forest.nn4, "./forest.nn4")
} else {
forest.nn4 = readRDS("./forest.nn4")
}
forest.model.nn4.valid = forest.valid4
idx = grep("CoverType", colnames(forest.valid4))
forest.model.nn4.valid = forest.model.nn4.valid[,-idx]
# need to break out factors to columns
#idxs = grep("forest.zone", colnames(forest.nn4.model))
m = dummyVars(" ~ .", data = forest.model.nn4.valid)
m = predict(m, newdata = forest.model.nn4.valid)
# remove one each of the factor predictors, but leave all of the CoverType factors
n = colnames(m)
idxs = grep("forest.area.Area1|forest.zone.trans.zone27", n)
m = m[,-idxs]
colnames(m) = gsub("area.Area","areaArea",colnames(m))
colnames(m) = gsub("zone.trans","zonetrans",colnames(m))
forest.nn4.pred = predict(forest.nn4$finalModel, newdata=m, type="class")
#table(forest.nn4.pred)
forest.nn4.pred = gsub("CoverType","",forest.nn4.pred)
forest.nn4.cm = caret::confusionMatrix(data=forest.nn4.pred, reference=forest.valid4$CoverType)
forest.nn4.kappa = forest.nn4.cm$overall[2]
forest.nn4.accuracy = forest.nn4.cm$overall[1]
#table(forest.nn4.pred)
#forest.nn4.kappa
## NN5 ##########################################
############################################################
#model with soil info and assured low class observations with all training
#data using best result from CV analysis on smaller training data set
#15 nodes, 0.05 decay
set.seed(444)
forest.model.nn5 = forest.train4
#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn5))
#forest.model.nn5[,idxs] = scale(forest.model.nn5[,idxs], center = TRUE, scale = TRUE)
if (build) {
forest.nn5 = nnet(CoverType ~ . , data=forest.model.nn5, linout=FALSE, size=15, maxit=2000, decay=0.05, trace=FALSE)
saveRDS(forest.nn5, "./forest.nn5")
} else {
forest.nn5 = readRDS("./forest.nn5")
}
forest.model.nn5.valid = forest.valid4
idx = grep("CoverType", colnames(forest.valid4))
forest.model.nn5.valid = forest.model.nn5.valid[,-idx]
#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn5.valid))
#forest.model.nn5.valid[,idxs] = scale(forest.model.nn5.valid[,idxs], center = TRUE, scale = TRUE)
forest.nn5.pred = predict(forest.nn5, newdata=forest.model.nn5.valid, type="class")
forest.nn5.cm = caret::confusionMatrix(data=forest.nn5.pred, reference=forest.valid4$CoverType)
forest.nn5.kappa = forest.nn5.cm$overall[2]
forest.nn5.accuracy = forest.nn5.cm$overall[1]
#table(forest.nn5.pred)
#forest.nn5.kappa
## NN6 ##########################################
#model with soil info, two layer (5,2) nodes, 0.01 decay
library(neuralnet)
set.seed(444)
forest.nn6.model = forest.train4
#forest.nn5.model = forest.nn5.model[1:1000,]
idxs = grep("forest.zone", colnames(forest.nn6.model))
m = dummyVars(" ~ .", data = forest.nn6.model[,-idxs])
m = predict(m, newdata = forest.nn6.model)
# remove one each of the factor predictors, but leave all of the CoverType factors
n = colnames(m)
idxs = grep("forest.area.Area1", n)
m = m[,-idxs]
n = colnames(m)
left = paste(n[grep("CoverType",n)], collapse = " + ")
right = paste(n[-grep("CoverType",n)], collapse = " + ")
fnn = as.formula(paste(left, right, sep = " ~ "))
if (build) {
#forest.nn6 = neuralnet(fnn, data=m, hidden=c(15,9), linear.output=FALSE, learningrate = 0.5)
#saveRDS(forest.nn6, "./forest.nn6")
} else {
#forest.nn6 = readRDS("./forest.nn6")
}
#idxs = grep("forest.zone", colnames(forest.valid4))
#m.test = dummyVars(" ~ .", data = forest.valid4[,-idxs])
#m.test = predict(m.test, newdata = forest.valid4)
#n = colnames(m.test)
#idxs = grep("forest.area.Area1|CoverType", n)
#m.test = m.test[,-idxs]
#forest.nn5.pred = neuralnet::compute(forest.nn5, m.test)$net.result
#head(forest.nn5.pred)
#s = apply(forest.nn5.pred,1,function(x){
#  return(which.is.max(x))
#return(which(x == max(x), arr.ind = TRUE))
#})
############################################################
set.seed(444)
forest.model.nn7 = forest.train4
#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn7))
#forest.model.nn7[,idxs] = scale(forest.model.nn7[,idxs], center = TRUE, scale = TRUE)
if (build) {
forest.model.nn7$Y = class.ind(forest.model.nn7$CoverType)
# delete the old target variable
forest.model.nn7$CoverType=NULL
forest.nn7 = nnet(Y ~ . , data=forest.model.nn7, linout=FALSE, size=15, maxit=2000, decay=0.05, trace=FALSE, softmax=TRUE)
saveRDS(forest.nn7, "./forest.nn7")
} else {
forest.nn7 = readRDS("./forest.nn7")
}
forest.model.nn7.valid = forest.valid4
idx = grep("CoverType", colnames(forest.valid4))
forest.model.nn7.valid = forest.model.nn7.valid[,-idx]
#idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn7.valid))
#forest.model.nn7.valid[,idxs] = scale(forest.model.nn7.valid[,idxs], center = TRUE, scale = TRUE)
forest.nn7.pred = predict(forest.nn7, newdata=forest.model.nn7.valid, type="class")
forest.nn7.cm = caret::confusionMatrix(data=forest.nn7.pred, reference=forest.valid4$CoverType)
forest.nn7.kappa = forest.nn7.cm$overall[2]
forest.nn7.accuracy = forest.nn7.cm$overall[1]
### add code for the best nn performer's accuracy, kappa, f1, and boxplot of f1
#barplot(forest.nn1.cm$byClass[,7])
f1 <- as.data.frame(forest.nn5.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
ba <- as.data.frame(forest.nn1.cm$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy )) +
geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
forest.4 <- readRDS("forest.4.rds")
set.seed(456)
intrain2<-createDataPartition(y=forest.4$CoverType,p=0.05,list=FALSE)
forest.4.train<-forest.4[intrain2,]
forest.4.test<-forest.4[-intrain2,]
set.seed(7)
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
# run the RFE algorithm - Backwards Feature Selection with Kappa as metric
#results <- rfe(CoverType ~ ., data = forest.3, metric = "Kappa", rfeControl=control)
#saveRDS(results, "./results.rfe.rds")
results <- readRDS("results.rfe.rds")
# summarize the results
#print(results)
# list the chosen features
rfe.predictors <- predictors(results)
# plot the results
plot(results, type=c("g", "o"))
rfe.pred <- data.frame(rfe.predictors)
kable(rfe.pred, caption= "RFE Predictors", format="pandoc")
control <- trainControl(method="repeatedcv", number=5, repeats=3, search = "random")
metric <- "Kappa"
set.seed(345)
mtry <- sqrt(ncol(forest.4.train))
#rf.mod1 <- train(CoverType~ Elevation + HDist.FirePoint + HDist.Roadway + trans.LDist.Hydrology +
#+  VDist.Hydrology + Hillshade.3pm + Hillshade.12pm + Aspect +
#+  HDist.Hydrology + interElAr3 + Slope + interElAr1 + SoilType22 +
#+  SoilType23 + SoilType2 + SoilType33, data=forest.4.train, method="rf",
#+ metric=metric,tuneLength=15, trControl=control)
rf.mod1 <- readRDS("rf.mod1.rds")
plot(rf.mod1)
pred.rf1 = predict(rf.mod1$finalModel, newdata=forest.4.test )
cm.rf1 = confusionMatrix(data=pred.rf1, forest.4.test$CoverType)
library(pander)
pander(cm.rf1$table)
#cm.rf1
f1 <- as.data.frame(cm.rf1$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
ba <- as.data.frame(cm.rf1$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
set.seed(444)
idxs.soil = grep("Soil", colnames(forest.4))
temp.soil = forest.4[,idxs.soil]
soil.pca = prcomp(temp.soil, scale = F)
soil.pca.x = soil.pca$x
colnames(soil.pca.x) <- c(paste0("soil.pca.pc",as.character(1:ncol(soil.pca.x))))
forest.4 <- cbind(forest.4, soil.pca.x[,1:16]) #90.7% of importantance
set.seed(456)
intrain3<-createDataPartition(y=forest.4$CoverType,p=0.1,list=FALSE)
forest.4.train1<-forest.4[intrain3,]
forest.4.test1<-forest.4[-intrain3,]
control <- trainControl(method="repeatedcv", number=5, repeats=3, search="grid")
set.seed(456)
tunegrid <- expand.grid(.mtry=c(1:15))
#rf_gridsearch <- train(CoverType ~ Elevation + Aspect + Slope + HDist.Hydrology +
#               + VDist.Hydrology + HDist.Roadway + Hillshade.9am + Hillshade.12pm
#              + Hillshade.3pm + HDist.FirePoint + Area1 + Area2
#               + Area3+ Area4 + trans.LDist.Hydrology + interElAr1 + interElAr2
#               + interElAr3 + interElAr4 + below.water + soil.pca.pc1 + soil.pca.pc2
#               + soil.pca.pc3 + soil.pca.pc4 +  soil.pca.pc5 + soil.pca.pc6 + soil.pca.pc7
#               + soil.pca.pc8 + soil.pca.pc9+  soil.pca.pc10+ soil.pca.pc11
#               + soil.pca.pc12 + soil.pca.pc13+ soil.pca.pc14+ soil.pca.pc15
#               + soil.pca.pc16,
#               data=forest.4.train1, method="rf", metric="Kappa", tuneGrid=tunegrid, trControl=control)
#saveRDS(rf_gridsearch, "./rf_gridsearch.rds")
rf_gridsearch <- readRDS("rf_gridsearch.rds")
plot(rf_gridsearch)
pred.rf2 = predict(rf_gridsearch$finalModel, newdata=forest.4.test1 )
cm.rf2 = confusionMatrix(data=pred.rf2, forest.4.test1$CoverType)
library(pander)
pander(cm.rf2$table)
#cm.rf2
f1 <- as.data.frame(cm.rf2$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
ba <- as.data.frame(cm.rf2$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
set.seed(444)
forest.model.lda1 = forest.train4
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.lda1))
forest.model.lda1[,idxs] = scale(forest.model.lda1[,idxs], center = TRUE, scale = TRUE)
forest.lda1 <- train(CoverType ~ .,  data = forest.model.lda1,
method = "lda",
metric = "Kappa",
preProc = c("center", "scale"))
saveRDS(forest.lda1, "./forest.lda1.rds")
forest.lda1 <- readRDS("./forest.lda1.rds")
forest.model.lda1.valid = forest.valid4[,-idx]
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.lda1.valid))
forest.model.lda1.valid[,idxs] = scale(forest.model.lda1.valid[,idxs], center = TRUE, scale = TRUE)
pred.lda1 = predict(forest.lda1, newdata=forest.model.lda1.valid)
forest.lda1.cm = confusionMatrix(data=pred.lda1, forest.model.lda1.valid$CoverType)
forest.model.lda1.valid$CoverType
forest.model.lda1.valid = forest.valid4
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.lda1.valid))
forest.model.lda1.valid[,idxs] = scale(forest.model.lda1.valid[,idxs], center = TRUE, scale = TRUE)
pred.lda1 = predict(forest.lda1, newdata=forest.model.lda1.valid)
forest.lda1.cm = confusionMatrix(data=pred.lda1, forest.model.lda1.valid$CoverType)
forest.lda1.kappa = forest.lda1.cm$overall[2]
forest.lda1.accuracy = forest.lda1.cm$overall[1]
pander(forest.lda1.cm$table)
forest.lda1.kappa
forest.lda1.accuracy
f1 <- as.data.frame(forest.lda1.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
library(class)
library(caret)
library(knncat)
# temp make training set smaller.
set.seed(444)
forest.train.knn <- na.omit(forest.train4)
forest.valid.knn <- na.omit(forest.valid4)
names(forest.train.knn)
#prep data for centering and scaling by removing qualititative variables
forest.train.x <- forest.train.knn[,-c(4,25,26)]
forest.train.y <- forest.train.knn[,4]
forest.valid.x <- forest.valid.knn[,-c(4,25,26)]
forest.valid.y <- forest.valid.knn[,4]
#normalize and standardize training data
df.mean.train <- apply(forest.train.x, 2, mean)
df.sd.train <- apply(forest.train.x, 2, sd)
df.std.train <- t((t(forest.train.x)-df.mean.train)/df.sd.train) #standardize to have 0 mean and unit sd
#apply(df.std.train, 2, mean) # check zero mean
#apply(df.std.train, 2, sd) # check unit sd
forest.train.knn3 <-df.std.train
forest.train.knn3 <- cbind(df.std.train,
forest.train.knn$CoverType,
forest.train.knn$forest.area,
forest.train.knn$forest.zone)
colnames(forest.train.knn3)[24] <- "CoverType"
colnames(forest.train.knn3)[25] <- "forest.area"
colnames(forest.train.knn3)[26] <- "forest.zone"
forest.train.knn3 <- as.data.frame(forest.train.knn3)
forest.train.knn3$CoverType <- as.factor(forest.train.knn3$CoverType)
forest.train.knn3$forest.area <- as.factor(forest.train.knn3$forest.area)
forest.train.knn3$forest.zone <- as.factor(forest.train.knn3$forest.zone)
#normalize and standardize validation data
df.mean.valid <- apply(forest.valid.x, 2, mean)
df.sd.valid <- apply(forest.valid.x, 2, sd)
df.std.valid <- t((t(forest.valid.x)-df.mean.valid)/df.sd.valid) #standardize to have 0 mean and unit sd
#apply(df.std.valid, 2, mean) # check zero mean
#apply(df.std.valid, 2, sd) # check unit sd
forest.valid.knn3 <- df.std.valid
forest.valid.knn3 <- cbind(df.std.valid,
forest.valid.knn$CoverType,
forest.valid.knn$forest.area,
forest.valid.knn$forest.zone)
colnames(forest.valid.knn3)[24] <- "CoverType"
colnames(forest.valid.knn3)[25] <- "forest.area"
colnames(forest.valid.knn3)[26] <- "forest.zone"
forest.valid.knn3 <- as.data.frame(forest.valid.knn3)
forest.valid.knn3$CoverType <- as.factor(forest.valid.knn3$CoverType)
forest.valid.knn3$forest.area <- as.factor(forest.valid.knn3$forest.area)
forest.valid.knn3$forest.zone <- as.factor(forest.valid.knn3$forest.zone)
#table(forest.train.knn3[24])
#table(forest.valid.knn3[24])
#str(forest.train.y[24])
forest.train.knn3.x <- forest.train.knn3[,-c(24)]
forest.train.knn3.y <- forest.train.knn3[24]
forest.valid.knn3.x <- forest.valid.knn3[,-c(24)]
forest.valid.knn3.y <- forest.valid.knn3[24]
#K-Fold Cross Validation
set.seed(1)
idx <- createFolds(forest.train.y , k=10)
sapply(idx, length)
head(forest.train.knn[,4])
head(forest.train.knn3[24])
#Optimize K
ks <- 1:12
res <- sapply(ks, function(k) {
##try out each version of k from 1 to 12
res.k <- sapply(seq_along(idx), function(i) {
##loop over each of the 10 cross-validation folds
##predict the held-out samples using k nearest neighbors
knn.pred <- knn(forest.train.knn3.x[-idx[[1]] , ],
forest.valid.knn3.x[ idx[[1]], ],
forest.train.y[-idx[[1]] ],
k = k)
##the ratio of misclassified samples
mean(forest.valid.y[ idx[[i]] ] != knn.pred)
})
##average over the 10 folds
mean(res.k)
})
forest.4 <- readRDS("forest.4b.rds")
set.seed(456)
intrain2<-createDataPartition(y=forest.4$CoverType,p=0.1,list=FALSE)
forest.4.train<-forest.4[intrain2,]
forest.4.test<-forest.4[-intrain2,]
lr.mod1 <- train(CoverType ~ ., data=forest.4.train, method="multinom")
library(e1071)
set.seed(444)
forest.model.svm1 = sample_n(forest.train4, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1))
forest.model.svm1[,idxs] = scale(forest.model.svm1[,idxs], center = TRUE, scale = TRUE)
forest.svm.1 <- svm(CoverType ~ ., method = "class", data = forest.model.svm1)
#forest.svm.1
saveRDS(forest.svm.1, "./forest.svm1.rds")
forest.model.svm1.valid = forest.valid4
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1.valid))
forest.model.svm1.valid[,idxs] = scale(forest.model.svm1.valid[,idxs], center = TRUE, scale = TRUE)
pred.svm1 = predict(forest.svm.1, newdata=forest.model.svm1.valid)
#saveRDS(pred.svm1, "./pred.svm1.rds")
pred.svm1 <- readRDS("./pred.svm1.rds")
tab.svm <- table("Predicted Class" = pred.svm1, "Actual" = forest.model.svm1.valid$CoverType)
#tab.svm
saveRDS(pred.svm1, "./pred.svm1.rds")
forest.svm1.cm <-confusionMatrix(data=pred.svm1, forest.model.svm1.valid$CoverType)
forest.svm1.kappa = forest.svm1.cm$overall[2]
forest.svm1.accuracy = forest.svm1.cm$overall[1]
pander(forest.svm1.cm$table)
f1 <- as.data.frame(forest.svm1.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
forest.svm1.accuracy
f1 <- as.data.frame(forest.lda1.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
pander(forest.lda1.cm$table)
forest.4 <- readRDS("forest.4.rds")
set.seed(456)
intrain2<-createDataPartition(y=forest.4$CoverType,p=0.05,list=FALSE)
forest.4.train<-forest.4[intrain2,]
forest.4.test<-forest.4[-intrain2,]
ba <- as.data.frame(forest.lda1.cm$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
ba <- as.data.frame(forest.svm1.cm$byClass[,11])
colnames(ba) <- "Balanced_Accuracy"
ba$Class <- row.names(ba)
ggplot(data=ba, aes(x=Class, y = Balanced_Accuracy)) +
geom_bar(stat="identity", width=0.5) + ggtitle("Balanced Accuracy")
#add Neural Network models, K Nearest Neighbor and Logistic Regression
models = c("Neural Network- 15 Nodes","Random Forest","Random Forest w PCA", "Linear Discriminant Analysis","Support Vector Machines")
stats = c("Model", "Accuracy", "Kappa")
accuracy = round(c(forest.nn5.accuracy,cm.rf1$overall[1],cm.rf2$overall[1],forest.lda1.accuracy,forest.svm1.accuracy),
digits = 3)
kappa = round(c(forest.nn5.kappa,cm.rf1$overall[2],cm.rf2$overall[2],forest.lda1.kappa,forest.svm1.kappa),
digits = 3)
summary_table = cbind(models,accuracy,kappa)
colnames(summary_table) = stats
rownames(summary_table) = NULL
pander(summary_table, justify = "left")
lr.mod1.cm[1]
forest.4 <- readRDS("forest.4b.rds")
set.seed(456)
intrain2<-createDataPartition(y=forest.4$CoverType,p=0.1,list=FALSE)
forest.4.train<-forest.4[intrain2,]
forest.4.test<-forest.4[-intrain2,]
#saveRDS(lr.mod1, "lr.mod1.rds")
lr.mod1 <- readRDS("lr.mod1.rds")
#Predict on Validation Set
pred.lr.mod1 <- predict.train(lr.mod1, newdata = forest.4.test)
xtab <- table(pred.lr.mod1, forest.4.test$CoverType )
lr.mod1.cm <- confusionMatrix(xtab)
#lr.mod1.cm
lr.mod1.cm[1]
