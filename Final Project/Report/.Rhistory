cm.svm1 = confusionMatrix(data=pred.svm1, wine$Type)
??varImpPlot
saveRDS(cm.nn2, "./cm.nn2.rds")
kable(cm.rf1$table, caption = "Confusion Table for Random Forest Model 1 - In-Sample", format = "pandoc")
kable(cm.svm1$tablecaption,  "Confusion Table for Support Vector Model", format = "pandoc"))
kable(cm.svm1$tablecaption,  "Confusion Table for Support Vector Model", format = "pandoc")
kable(cm.svm1$table,  "Confusion Table for Support Vector Model", format = "pandoc")
kable(cm.svm1$table,  "Confusion Table for Support Vector Model", format = "pandoc")
pander(cm.svm1$table)
pander(cm.svm1$table)
cm.svm1
saveRDS(cm.svm1, "./cm.svm1.rds")
saveRDS(cm.nn1, "./cm.nn1.rds")
setwd("~/Documents/MSPA/MSPA 454/mspa454/Final Project/Report")
# read in the data, create dataframe
gz = gzfile('data/covtype.data.gz','rt')
knitr::opts_chunk$set(echo = FALSE)
# read in the data, create dataframe
gz = gzfile('data/covtype.data.gz','rt')
forest.orig = read.csv(gz,header=F)
forest.orig.colnames = t(read.csv('data/covtyp.colnames.csv',header=F))
colnames(forest.orig) = forest.orig.colnames
# identify continuous variables
forest.var.continuous = c('Elevation','Aspect','Slope', 'HDist.Hydrology', 'VDist.Hydrology',
'HDist.Roadway', 'Hillshade.9am', 'Hillshade.12pm', 'Hillshade.3pm',
'HDist.FirePoint')
# for speed, will perform eda on subset until ready to do a full run
set.seed(33)
forest = forest.orig[sample(nrow(forest.orig),20000),]
forest.var.discrete.indices = grep("^Area|^SoilType|CoverType", colnames(forest))
forest[,forest.var.discrete.indices] = as.factor(unlist(forest[,forest.var.discrete.indices]))
forest.numeric = as.data.frame(sapply(forest,as.numeric))
covertype.names = c('Spruce-fir','Lodgepole Pine','Ponderosa Pine','Cottonwood-Willow','Aspen','Douglas-fir','Krummholz')
forest$CoverType[forest$CoverType==1] = 'Spruce-fir'
forest$CoverType[forest$CoverType==2] = 'Lodgepole Pine'
forest$CoverType[forest$CoverType==3] = 'Ponderosa Pine'
forest$CoverType[forest$CoverType==4] = 'Cottonwood-Willow'
forest$CoverType[forest$CoverType==5] = 'Aspen'
forest$CoverType[forest$CoverType==6] = 'Douglas-fir'
forest$CoverType[forest$CoverType==7] = 'Krummholz'
# add Area column
# are any in multiple areas? NO. all belong to only one area
idx = grep("Area", colnames(forest))
temp = forest.numeric[,idx]
temp.rows = temp[apply(temp,1,sum) > 1,]
temp$Z.Area = apply(temp,1,function(x) {
return(which.max(x))
})
forest.numeric$Z.Area = temp$Z.Area
forest.scaled = as.data.frame(scale(forest.numeric))
library(lattice)
library(ggplot2)
library(corrplot)
library(MASS)
library(caret)
library(car)
library(DMwR)
library(dplyr)
library(doMC)
# read in the data, create dataframe
gz = gzfile('data/covtype.data.gz','rt')
forest.orig = read.csv(gz,header=F)
forest.orig.colnames = t(read.csv('data/covtyp.colnames.csv',header=F))
colnames(forest.orig) = forest.orig.colnames
# identify continuous variables
forest.var.continuous = c('Elevation','Aspect','Slope', 'HDist.Hydrology', 'VDist.Hydrology',
'HDist.Roadway', 'Hillshade.9am', 'Hillshade.12pm', 'Hillshade.3pm',
'HDist.FirePoint')
# for speed, will perform eda on subset until ready to do a full run
set.seed(33)
forest = forest.orig[sample(nrow(forest.orig),20000),]
forest.var.discrete.indices = grep("^Area|^SoilType|CoverType", colnames(forest))
forest[,forest.var.discrete.indices] = as.factor(unlist(forest[,forest.var.discrete.indices]))
forest.numeric = as.data.frame(sapply(forest,as.numeric))
covertype.names = c('Spruce-fir','Lodgepole Pine','Ponderosa Pine','Cottonwood-Willow','Aspen','Douglas-fir','Krummholz')
forest$CoverType[forest$CoverType==1] = 'Spruce-fir'
forest$CoverType[forest$CoverType==2] = 'Lodgepole Pine'
forest$CoverType[forest$CoverType==3] = 'Ponderosa Pine'
forest$CoverType[forest$CoverType==4] = 'Cottonwood-Willow'
forest$CoverType[forest$CoverType==5] = 'Aspen'
forest$CoverType[forest$CoverType==6] = 'Douglas-fir'
forest$CoverType[forest$CoverType==7] = 'Krummholz'
# add Area column
# are any in multiple areas? NO. all belong to only one area
idx = grep("Area", colnames(forest))
temp = forest.numeric[,idx]
temp.rows = temp[apply(temp,1,sum) > 1,]
temp$Z.Area = apply(temp,1,function(x) {
return(which.max(x))
})
forest.numeric$Z.Area = temp$Z.Area
forest.scaled = as.data.frame(scale(forest.numeric))
library(lattice)
library(ggplot2)
library(corrplot)
library(MASS)
library(caret)
library(car)
library(DMwR)
library(dplyr)
library(randomForest)
library(nnet)
library(neuralnet)
cover_types <- c("Spruce/Fir", "Lodgepole Pine", "Ponderosa Pine", "Cottonwood/Willow", "Aspen",
"Douglas/Fir", "Krummholz")
instances <- c(211840, 283301, 35754, 2747, 9493, 17367, 20510)
ct.df <- data.frame(cover_types, instances)
colnames(ct.df) <- c("Cover Type", "Number of Observations")
knitr::kable(ct.df, caption = "Cover Type Classes", format="pandoc")
features <- c("Elevation", "Aspect", "Slope", "HDist.Hydrology", "VDist.Hydrology",
"HDist.Roadway", "Hillshade.9am", "Hillshade.12pm", "Hillshade.3pm",
"HHDist.FirePoint", "Area", "SoilType")
descriptions <- c("Elevation in meters", "Aspect in degrees aziumuth", "Slope in degrees",
"Horizontal distance to nearest surface water feature in meters",
"Vertical distance to nearest surface water feature in meters",
"Horizontal distance to nearest roadway in meters", "Hillshade index at 9am, summer solstice",
"Hillshade index at noon, summer soltice", "Hillshade index at 3pm, summer solstice",
"Horizontal Distance to nearest wildfire ignition points", "Wilderness area designation - 4 binary areas",
"Soil Type designation - 40 binary values")
features.df <- data.frame(features, descriptions)
colnames(features.df) <- c("Feature", "Descriptions")
knitr::kable(features.df, caption = "Features", format="pandoc")
library(scales)
ggplot(as.data.frame(table(forest.orig$CoverType)), aes(x=Var1, y = Freq)) + ggtitle("Forest Cover
Frequency by Class") + geom_bar(stat = "identity", fill="#1f78b4", width=.5,
color="black") + xlab("Cover Type") + scale_y_continuous(name="Frequency", labels = comma)
options(digits=3)
my.summary <- function(x,...){
c(mean=round(mean(x, ...), digits = 4),
sd=round(sd(x, ...), digits=4),
median=median(x, ...),
min=min(x, ...),
max=max(x,...),
nmiss=sum(is.na(x,...)),
type="Continuous")
}
forest.stats= apply(forest.orig[,1:10], 2, my.summary)
library(knitr)
kable(t(forest.stats), caption= "Summary Statistics for Continuous Data", format="pandoc")
## area
forest.area= forest.orig[11:14]
summary.area <- data.frame(
Name = character(),
Count = numeric(),
stringsAsFactors = F)
for (i in 1:4){
summary.area[i,1] <- names(forest.area[i])
summary.area[i,2] <- sum(forest.area[,i])
}
area<-summary.area[with(summary.area,order(-Count)),]
kable(area,caption= "Area Type Counts", format="pandoc", row.names = F)
## soil
forest.soil= forest.orig[15:54]
summary.soil <- data.frame(
Name = character(),
Count = numeric(),
stringsAsFactors = F)
for (i in 1:40){
summary.soil[i,1] <- names(forest.soil[i])
summary.soil[i,2] <- sum(forest.soil[,i])
}
soil<-summary.soil[with(summary.soil,order(-Count)),]
kable(soil, caption= "Soil Type Counts", format="pandoc", row.names = F)
corrplot(cor(forest[, forest.var.continuous]),
tl.col = "black", tl.cex = 0.8, tl.srt = 45,
cl.cex = 0.8, pch.cex = 0.8, diag = FALSE,
type="lower",
addCoefasPercent = TRUE, addCoef.col = TRUE,number.cex = .6) #Matt added to show correlation amounts
# transform Hillshade.12pm and Vdist.Hydrology
forest.new= forest.orig
#forest.new$trans.Hillshade.12pm = log(forest.new$Hillshade.12pm)
#forest.new$trans.VDist.Hydrology = preProcess(forest.new$VDist.Hydrology, method = "YeoJohnson")
forest.new$trans.LDist.Hydrology <- sqrt(forest.new$VDist.Hydrology^2 + forest.new$HDist.Hydrology^2)
# Soil Type to Climate Zone Mapping
forest.new$trans.zone27 <- rowSums(forest.new[,c("SoilType1", "SoilType2","SoilType3","SoilType4", "SoilType5","SoilType6")])
forest.new$trans.zone35 <- rowSums(forest.new[,c("SoilType7", "SoilType8")])
forest.new$trans.zone42 <- forest.new$SoilType9
forest.new$trans.zone47 <- rowSums(forest.new[,c("SoilType10", "SoilType11","SoilType12","SoilType13")])
forest.new$trans.zone51 <- rowSums(forest.new[,c("SoilType14", "SoilType15")])
forest.new$trans.zone61 <- rowSums(forest.new[,c("SoilType16", "SoilType17")])
forest.new$trans.zone67 <- forest.new$SoilType18
forest.new$trans.zone71 <- rowSums(forest.new[,c("SoilType19", "SoilType20","SoilType21")])
forest.new$trans.zone72 <- rowSums(forest.new[,c("SoilType22", "SoilType23")])
forest.new$trans.zone77 <- rowSums(forest.new[,c("SoilType24", "SoilType25","SoilType26","SoilType27", "SoilType28",
"SoilType29", "SoilType30","SoilType31","SoilType32", "SoilType33", "SoilType34")])
forest.new$trans.zone87 <- rowSums(forest.new[,c("SoilType35", "SoilType36","SoilType37","SoilType38", "SoilType39","SoilType40")])
#PCA
set.seed(444)
idxs.soil = grep("Soil", colnames(forest.new))
temp.soil = forest.new[,idxs.soil]
soil.pca = prcomp(temp.soil, scale = F)
soil.pca.x = soil.pca$x
colnames(soil.pca.x) <- c(paste0("soil.pca.pc",as.character(1:ncol(soil.pca.x))))
#summary(soil.pca)$importance[3,]
forest.new <- cbind(forest.new, soil.pca.x[,1:16]) #90.7% of importantance
idxs.zone = grep("trans.zone", colnames(forest.new))
temp.zone = forest.new[,idxs.zone]
zone.pca = prcomp(temp.zone, scale = F)
zone.pca.x = zone.pca$x
colnames(zone.pca.x) <- c(paste0("zone.pca.pc",as.character(1:ncol(zone.pca.x))))
#summary(zone.pca)$importance[3,]
forest.new <- cbind(forest.new, zone.pca.x[,1:6]) #99.7% of importantance
par(mfrow=c(1,2))
plot(summary(soil.pca)$importance[3,], xlab="Principal Components", ylab="Importance",
main="Soil Type PCA Importance Plot", pch=20, col="red")
plot(summary(zone.pca)$importance[3,], xlab="Principal Components", ylab="Importance",
main="Soil Zone PCA Importance Plot", pch=20, col="blue")
par(mfrow=c(1,1))
#rm(list = c(temp.soil, temp.zone))
idxs_trans = grep("trans", colnames(forest.new))
forest.transforms= forest.new[,idxs_trans]
idxs_pca = grep("PC|shade.pca", colnames(forest.new))
forest.pca= forest.new[,idxs_pca]
idxs_buck = grep("buck", colnames(forest.new))
forest.bucketing= forest.new[,idxs_buck]
#Training/Test Splitting
set.seed(330)
fraction.train <- .7 # Enter Training Set Size
fraction.valid <- 1 - fraction.train
size.train <- fraction.train*nrow(forest.new)
size.valid <- nrow(forest.new) - size.train
indices.train <- sort(sample(seq_len(nrow(forest.new)), size=size.train))
indices.valid <- setdiff(seq_len(nrow(forest.new)), indices.train)
forest.train <- forest.new[indices.train,]
forest.valid <- forest.new[indices.valid,]
#Remove SoilTypes and Aspect, Slope and Hillsides
forest.train.rm <- forest.train[,-c(2,3,4,7,8,9, 15:54,68:83)]
forest.model = forest.new
### update forest.new with any renames or consolidations
# rename some predictors
forest.model.colnames = colnames(forest.model)
idxs = grep("^PC",forest.model.colnames)
forest.model.colnames[idxs] = paste("pca.soil.",forest.model.colnames[idxs],sep = "")
colnames(forest.model) = forest.model.colnames
# convert 4 area predictors to one factor variable
idxs = grep("^Area",colnames(forest.model))
mat = as.matrix(forest.model[,idxs])
forest.model$forest.area = factor(mat%*%(1:ncol(mat)), labels = colnames(mat))
mat = NULL
forest.model[,idxs] = NULL
# convert zones into one factor variable
idxs = grep("trans.zone",colnames(forest.model))
mat = as.matrix(forest.model[,idxs])
forest.model$forest.zone = factor(mat%*%(1:ncol(mat)), labels = colnames(mat))
mat = NULL
forest.model[,idxs] = NULL
# convert to factors where needed
idxs = grep("Area|SoilType|CoverType|trans.zone",colnames(forest.model))
forest.model[,idxs] = lapply(forest.model[,idxs], as.factor)
#Training/Test Splitting
set.seed(330)
fraction.train = .7 # Enter Training Set Size
fraction.valid = 1 - fraction.train
size.train = fraction.train*nrow(forest.model)
size.valid = nrow(forest.model) - size.train
indices.train = sort(sample(seq_len(nrow(forest.model)), size=size.train))
indices.valid = setdiff(seq_len(nrow(forest.model)), indices.train)
# create a couple versions of the model to try out with the algorithms
forest.model1 = forest.model # bare bones model without Soil anything
forest.model2 = forest.model # bare bones model with Soil pca
# remove the unwanted variables for modeling
idxs = grep("^SoilType|^Aspect|^Hillshade|^Slope|^HDist.Hydrology|VDist.Hydrology|soil.pca|zone.pca",colnames(forest.model))
forest.model1[,idxs] = NULL
idxs = grep("^Aspect|^Hillshade|^Slope|^HDist.Hydrology|VDist.Hydrology|^SoilType|zone.pca",colnames(forest.model))
forest.model2[,idxs] = NULL
forest.train1 = forest.model1[indices.train,]
forest.valid1 = forest.model1[indices.valid,]
forest.train2 = forest.model2[indices.train,]
forest.valid2 = forest.model2[indices.valid,]
# model that makes sure the low model types are always present in a sample
set.seed(444)
sample4.tbl = table(forest.model2$CoverType)
forest.model4 = sample_n(forest.model2[forest.model2$CoverType==4,], 1917)
for (i in 1:7) {
cnt = sample4.tbl[i]
if (cnt > 100000) {
forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],20000))
} else if (cnt > 10000) {
forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],5000))
} else if (cnt > 3000) {
forest.model4 = rbind(forest.model4, sample_n(forest.model2[forest.model2$CoverType==i,],3000))
}
}
forest.train4 = forest.model4
forest.valid4 = forest.model4[indices.valid,]
rm(list = c('indices.train', 'indices.valid', 'size.train', 'size.valid'))
set.seed(444)
forest.model.lda1 = sample_n(forest.train1, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.lda1))
forest.model.lda1[,idxs] = scale(forest.model.lda1[,idxs], center = TRUE, scale = TRUE)
forest.lda1 <- train(CoverType ~ .,  data = forest.model.lda1,
method = "lda",
metric = "Kappa",
preProc = c("center", "scale"))
saveRDS(forest.lda1, "./forest.lda1.rds")
forest.model.lda1.valid = forest.valid1[,-idx]
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.lda1.valid))
forest.model.lda1.valid[,idxs] = scale(forest.model.lda1.valid[,idxs], center = TRUE, scale = TRUE)
pred.lda1 = predict(forest.lda1, newdata=forest.model.lda1.valid)
forest.lda1.cm = confusionMatrix(data=pred.lda1, forest.model.lda1.valid$CoverType)
forest.lda1.kappa = forest.lda1.cm$overall[2]
forest.lda1.accuracy = forest.lda1.cm$overall[1]
forest.lda1.kappa
forest.lda1.accuracy
library(e1071)
set.seed(444)
forest.model.svm1 = sample_n(forest.train1, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1))
forest.model.svm1[,idxs] = scale(forest.model.svm1[,idxs], center = TRUE, scale = TRUE)
#forest.svm.1 <- svm(CoverType ~ ., method = "class", data = forest.model.svm1)
#forest.svm.1
forest.svm1 <- readRDS("./forest.svm1.rds")
forest.model.svm1.valid = forest.valid1[,-idx]
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1.valid))
forest.model.svm1.valid[,idxs] = scale(forest.model.svm1.valid[,idxs], center = TRUE, scale = TRUE)
#pred.svm1 = predict(forest.svm.1, newdata=forest.model.svm1.valid)
#saveRDS(pred.svm1, "./pred.svm1.rds")
pred.svm1 <- readRDS("./pred.svm1.rds")
tab.svm <- table("Predicted Class" = pred.svm1, "Actual" = forest.model.svm1.valid$CoverType)
#tab.svm
control <- trainControl(method="repeatedcv", number=5, repeats=3, search = "random")
metric <- "Kappa"
set.seed(345)
mtry <- sqrt(ncol(forest.4.train))
forest.4 <- readRDS("forest.4.rds")
set.seed(456)
intrain2<-createDataPartition(y=forest.4$CoverType,p=0.05,list=FALSE)
forest.4.train<-forest.4[intrain2,]
forest.4.test<-forest.4[-intrain2,]
set.seed(7)
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=5)
# run the RFE algorithm - Backwards Feature Selection with Kappa as metric
#results <- rfe(CoverType ~ ., data = forest.3, metric = "Kappa", rfeControl=control)
#saveRDS(results, "./results.rfe.rds")
results <- readRDS("results.rfe.rds")
# summarize the results
#print(results)
# list the chosen features
rfe.predictors <- predictors(results)
# plot the results
plot(results, type=c("g", "o"))
control <- trainControl(method="repeatedcv", number=5, repeats=3, search = "random")
metric <- "Kappa"
set.seed(345)
mtry <- sqrt(ncol(forest.4.train))
#rf.mod1 <- train(CoverType~ Elevation + HDist.FirePoint + HDist.Roadway + trans.LDist.Hydrology +
#+  VDist.Hydrology + Hillshade.3pm + Hillshade.12pm + Aspect +
#+  HDist.Hydrology + interElAr3 + Slope + interElAr1 + SoilType22 +
#+  SoilType23 + SoilType2 + SoilType33, data=forest.4.train, method="rf",
#+ metric=metric,tuneLength=15, trControl=control)
rf.mod1 <- readRDS("rf.mod1.rds")
plot(rf.mod1)
pred.rf1 = predict(rf.mod1$finalModel, newdata=forest.4.test )
cm.rf1 = confusionMatrix(data=pred.rf1, forest.4.test$CoverType)
cm.rf1[1]
cm.rf1$overall[1]
cm.rf1$overall[2]
library(class)
library(caret)
library(knncat)
install.packages("knncat")
library(class)
library(caret)
library(knncat)
# temp make training set smaller.
set.seed(444)
forest.train.knn <- forest.train1[sample(nrow(forest.train1), 40000, replace = FALSE),]
colnames(forest.train1)
#Removing CoverType and Forest Zone Variables from model for now.
#Researching how to treat them
forest.train.x <- forest.train.knn[,-c(4,9,10)]
forest.train.y <- forest.train.knn[,9]
forest.train.knn[,9]
head(forest.train.knn)
#add K Nearest Neighbor and Logistic Regression
models = c("Neural Network Model 1","Neural Network Model 2","Neural Network Model 3","Neural Network Model 4","Neural Network Model 5","Random Forest","Random Forest w PCA", "Linear Discriminant Analysis","Support Vector Machines")
stats = c("Model", "Accuracy", "Kappa")
accuracy = round(c(forest.nn1.accuracy,forest.nn2.accuracy,forest.nn3.accuracy,forest.nn4.accuracy,forest.nn5.accuracy, cm.rf1$overall[1],cm.rf2$overall[1],forest.lda1.accuracy,forest.svm1.accuracy),
digits = 3)
library(nnet)
build = FALSE
## NN1 ##########################################
# model without soil info, 5 nodes, 0.01 decay
set.seed(444)
forest.model.nn1 = sample_n(forest.train1, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn1))
forest.model.nn1[,idxs] = scale(forest.model.nn1[,idxs], center = TRUE, scale = TRUE)
if (build) {
forest.nn1 = nnet(CoverType ~ . , data=forest.model.nn1, linout=FALSE, size=5, maxit=2000, decay=0.01, trace=FALSE)
saveRDS(forest.nn1, "./forest.nn1")
} else {
forest.nn1 = readRDS("./forest.nn1")
}
idx = grep("CoverType", colnames(forest.valid1))
forest.model.nn1.valid = forest.valid1[,-idx]
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.nn1.valid))
forest.model.nn1.valid[,idxs] = scale(forest.model.nn1.valid[,idxs], center = TRUE, scale = TRUE)
forest.nn1.pred = predict(forest.nn1, newdata=forest.model.nn1.valid, type="class")
#add Neural Network models, K Nearest Neighbor and Logistic Regression
models = c("Random Forest","Random Forest w PCA", "Linear Discriminant Analysis","Support Vector Machines")
stats = c("Model", "Accuracy", "Kappa")
accuracy = round(c(cm.rf1$overall[1],cm.rf2$overall[1],forest.lda1.accuracy,forest.svm1.accuracy),
digits = 3)
control <- trainControl(method="repeatedcv", number=5, repeats=3, search="grid")
set.seed(456)
tunegrid <- expand.grid(.mtry=c(1:15))
#rf_gridsearch <- train(CoverType ~ Elevation + Aspect + Slope + HDist.Hydrology +
#               + VDist.Hydrology + HDist.Roadway + Hillshade.9am + Hillshade.12pm
#              + Hillshade.3pm + HDist.FirePoint + Area1 + Area2
#               + Area3+ Area4 + trans.LDist.Hydrology + interElAr1 + interElAr2
#               + interElAr3 + interElAr4 + below.water + soil.pca.pc1 + soil.pca.pc2
#               + soil.pca.pc3 + soil.pca.pc4 +  soil.pca.pc5 + soil.pca.pc6 + soil.pca.pc7
#               + soil.pca.pc8 + soil.pca.pc9+  soil.pca.pc10+ soil.pca.pc11
#               + soil.pca.pc12 + soil.pca.pc13+ soil.pca.pc14+ soil.pca.pc15
#               + soil.pca.pc16,
#               data=forest.4.train1, method="rf", metric="Kappa", tuneGrid=tunegrid, trControl=control)
#saveRDS(rf_gridsearch, "./rf_gridsearch.rds")
rf_gridsearch <- readRDS("rf_gridsearch.rds")
plot(rf_gridsearch)
pred.rf2 = predict(rf_gridsearch$finalModel, newdata=forest.4.test1 )
set.seed(444)
idxs.soil = grep("Soil", colnames(forest.4))
temp.soil = forest.4[,idxs.soil]
soil.pca = prcomp(temp.soil, scale = F)
soil.pca.x = soil.pca$x
colnames(soil.pca.x) <- c(paste0("soil.pca.pc",as.character(1:ncol(soil.pca.x))))
forest.4 <- cbind(forest.4, soil.pca.x[,1:16]) #90.7% of importantance
set.seed(456)
intrain3<-createDataPartition(y=forest.4$CoverType,p=0.1,list=FALSE)
forest.4.train1<-forest.4[intrain3,]
forest.4.test1<-forest.4[-intrain3,]
control <- trainControl(method="repeatedcv", number=5, repeats=3, search="grid")
set.seed(456)
tunegrid <- expand.grid(.mtry=c(1:15))
#rf_gridsearch <- train(CoverType ~ Elevation + Aspect + Slope + HDist.Hydrology +
#               + VDist.Hydrology + HDist.Roadway + Hillshade.9am + Hillshade.12pm
#              + Hillshade.3pm + HDist.FirePoint + Area1 + Area2
#               + Area3+ Area4 + trans.LDist.Hydrology + interElAr1 + interElAr2
#               + interElAr3 + interElAr4 + below.water + soil.pca.pc1 + soil.pca.pc2
#               + soil.pca.pc3 + soil.pca.pc4 +  soil.pca.pc5 + soil.pca.pc6 + soil.pca.pc7
#               + soil.pca.pc8 + soil.pca.pc9+  soil.pca.pc10+ soil.pca.pc11
#               + soil.pca.pc12 + soil.pca.pc13+ soil.pca.pc14+ soil.pca.pc15
#               + soil.pca.pc16,
#               data=forest.4.train1, method="rf", metric="Kappa", tuneGrid=tunegrid, trControl=control)
#saveRDS(rf_gridsearch, "./rf_gridsearch.rds")
rf_gridsearch <- readRDS("rf_gridsearch.rds")
plot(rf_gridsearch)
pred.rf2 = predict(rf_gridsearch$finalModel, newdata=forest.4.test1 )
cm.rf2 = confusionMatrix(data=pred.rf2, forest.4.test1$CoverType)
library(pander)
pander(cm.rf2$table)
#add Neural Network models, K Nearest Neighbor and Logistic Regression
models = c("Random Forest","Random Forest w PCA", "Linear Discriminant Analysis","Support Vector Machines")
stats = c("Model", "Accuracy", "Kappa")
accuracy = round(c(cm.rf1$overall[1],cm.rf2$overall[1],forest.lda1.accuracy,forest.svm1.accuracy),
digits = 3)
library(e1071)
set.seed(444)
forest.model.svm1 = sample_n(forest.train1, 40000)
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1))
forest.model.svm1[,idxs] = scale(forest.model.svm1[,idxs], center = TRUE, scale = TRUE)
#forest.svm.1 <- svm(CoverType ~ ., method = "class", data = forest.model.svm1)
#forest.svm.1
forest.svm1 <- readRDS("./forest.svm1.rds")
forest.model.svm1.valid = forest.valid1[,-idx]
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1.valid))
forest.model.svm1.valid[,idxs] = scale(forest.model.svm1.valid[,idxs], center = TRUE, scale = TRUE)
#pred.svm1 = predict(forest.svm.1, newdata=forest.model.svm1.valid)
#saveRDS(pred.svm1, "./pred.svm1.rds")
pred.svm1 <- readRDS("./pred.svm1.rds")
tab.svm <- table("Predicted Class" = pred.svm1, "Actual" = forest.model.svm1.valid$CoverType)
forest.model.svm1.valid = forest.valid1
idxs = grep("Elevation|HDist|trans|shade",colnames(forest.model.svm1.valid))
forest.model.svm1.valid[,idxs] = scale(forest.model.svm1.valid[,idxs], center = TRUE, scale = TRUE)
#pred.svm1 = predict(forest.svm.1, newdata=forest.model.svm1.valid)
#saveRDS(pred.svm1, "./pred.svm1.rds")
pred.svm1 <- readRDS("./pred.svm1.rds")
tab.svm <- table("Predicted Class" = pred.svm1, "Actual" = forest.model.svm1.valid$CoverType)
#tab.svm
forest.svm1.cm <-confusionMatrix(data=pred.svm1, forest.model.svm1.valid$CoverType)
forest.svm1.kappa = forest.svm1.cm$overall[2]
forest.svm1.accuracy = forest.svm1.cm$overall[1]
#add Neural Network models, K Nearest Neighbor and Logistic Regression
models = c("Random Forest","Random Forest w PCA", "Linear Discriminant Analysis","Support Vector Machines")
stats = c("Model", "Accuracy", "Kappa")
accuracy = round(c(cm.rf1$overall[1],cm.rf2$overall[1],forest.lda1.accuracy,forest.svm1.accuracy),
digits = 3)
kappa = round(c(cm.rf1$overall[2],cm.rf2$overall[2],forest.lda1.kappa,forest.svm1.kappa),
digits = 3)
summary_table = cbind(models,accuracy,kappa)
colnames(summary_table) = stats
rownames(summary_table) = NULL
pander(summary_table, justify = "left")
plot(forest.lda1)
f1 <- as.data.frame(cm.rf2$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
pander(forest.lda1.cm$table)
pander(forest.svm1.cm$table)
f1 <- as.data.frame(forest.lda1.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
f1 <- as.data.frame(forest.svm1.cm$byClass[,7])
colnames(f1) <- "F1"
f1$Class <- row.names(f1)
ggplot(data=f1, aes(x=Class, y = F1)) +
geom_bar(stat="identity", width=0.5) + ggtitle("F1 Scores")
